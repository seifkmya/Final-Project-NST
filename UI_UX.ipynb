{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c6f291-9f2f-4e1f-a5da-010ff28af7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: pillow in /venv/main/lib/python3.12/site-packages (11.0.0)\n",
      "Collecting pillow\n",
      "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /venv/main/lib/python3.12/site-packages (from streamlit) (2.1.2)\n",
      "Requirement already satisfied: packaging<26,>=20 in /venv/main/lib/python3.12/site-packages (from streamlit) (25.0)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
      "  Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /venv/main/lib/python3.12/site-packages (from streamlit) (6.32.1)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /venv/main/lib/python3.12/site-packages (from streamlit) (2.32.4)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /venv/main/lib/python3.12/site-packages (from streamlit) (4.14.0)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /venv/main/lib/python3.12/site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.4)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /venv/main/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.5)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pandas-2.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading narwhals-2.5.0-py3-none-any.whl (407 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, watchdog, tzdata, toml, tenacity, smmap, rpds-py, pyarrow, pillow, narwhals, click, cachetools, blinker, attrs, referencing, pydeck, pandas, gitdb, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\u001b[2K  Attempting uninstall: pillow\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/23\u001b[0m [pyarrow]]\n",
      "\u001b[2K    Found existing installation: pillow 11.0.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/23\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling pillow-11.0.0:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/23\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled pillow-11.0.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/23\u001b[0m [pyarrow]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [streamlit]23\u001b[0m [streamlit]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed altair-5.5.0 attrs-25.3.0 blinker-1.9.0 cachetools-6.2.0 click-8.3.0 gitdb-4.0.12 gitpython-3.1.45 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 narwhals-2.5.0 pandas-2.3.2 pillow-11.3.0 pyarrow-21.0.0 pydeck-0.9.1 pytz-2025.2 referencing-0.36.2 rpds-py-0.27.1 smmap-5.0.2 streamlit-1.49.1 tenacity-9.1.2 toml-0.10.2 tzdata-2025.2 watchdog-6.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U streamlit pillow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c9fbf-8f75-4836-84a5-e683f920986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit Johnson Style Transfer UI\n",
    "# -------------------------------------------------\n",
    "# Features\n",
    "# - Upload or point to a Johnson-style .pth model and stylize single or multiple images\n",
    "# - GPU/CPU toggle, optional FP16 on CUDA\n",
    "# - Keep original resolution or auto-resize by max long side\n",
    "# - Side-by-side preview, progress bars, zip download for batch\n",
    "# - Safe state-dict loading (handles DataParallel 'module.' prefix)\n",
    "# -------------------------------------------------\n",
    "\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import zipfile\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "\n",
    "# --------------------- Transform Net (Johnson et al.) ---------------------\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel, stride):\n",
    "        super().__init__()\n",
    "        pad = kernel // 2\n",
    "        self.pad = nn.ReflectionPad2d(pad)\n",
    "        self.conv = nn.Conv2d(in_c, out_c, kernel, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.pad(x))\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvLayer(channels, channels, 3, 1)\n",
    "        self.in1   = nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.conv2 = ConvLayer(channels, channels, 3, 1)\n",
    "        self.in2   = nn.InstanceNorm2d(channels, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.in1(self.conv1(x)))\n",
    "        y = self.in2(self.conv2(y))\n",
    "        return x + y\n",
    "\n",
    "class UpsampleConvLayer(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel, upsample=None):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        self.pad = nn.ReflectionPad2d(kernel // 2)\n",
    "        self.conv = nn.Conv2d(in_c, out_c, kernel, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = F.interpolate(x, scale_factor=self.upsample, mode=\"nearest\")\n",
    "        return self.conv(self.pad(x))\n",
    "\n",
    "class TransformNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = ConvLayer(3, 32, 9, 1)\n",
    "        self.in1   = nn.InstanceNorm2d(32, affine=True)\n",
    "        self.conv2 = ConvLayer(32, 64, 3, 2)\n",
    "        self.in2   = nn.InstanceNorm2d(64, affine=True)\n",
    "        self.conv3 = ConvLayer(64, 128, 3, 2)\n",
    "        self.in3   = nn.InstanceNorm2d(128, affine=True)\n",
    "        # Residuals\n",
    "        self.res   = nn.Sequential(*[ResidualBlock(128) for _ in range(5)])\n",
    "        # Decoder\n",
    "        self.up1   = UpsampleConvLayer(128, 64, 3, upsample=2)\n",
    "        self.in4   = nn.InstanceNorm2d(64, affine=True)\n",
    "        self.up2   = UpsampleConvLayer(64, 32, 3, upsample=2)\n",
    "        self.in5   = nn.InstanceNorm2d(32, affine=True)\n",
    "        self.conv4 = ConvLayer(32, 3, 9, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.in1(self.conv1(x)))\n",
    "        y = F.relu(self.in2(self.conv2(y)))\n",
    "        y = F.relu(self.in3(self.conv3(y)))\n",
    "        y = self.res(y)\n",
    "        y = F.relu(self.in4(self.up1(y)))\n",
    "        y = F.relu(self.in5(self.up2(y)))\n",
    "        y = torch.tanh(self.conv4(y))\n",
    "        return (y + 1) / 2.0  # map from [-1,1] to [0,1]\n",
    "\n",
    "# --------------------- Helpers ---------------------\n",
    "@st.cache_data(show_spinner=False)\n",
    "def _sha1_bytes(b: bytes) -> str:\n",
    "    return hashlib.sha1(b).hexdigest()\n",
    "\n",
    "@st.cache_resource(show_spinner=False)\n",
    "def load_model(model_bytes: bytes | None, model_path: str | None, device_str: str):\n",
    "    \"\"\"Load and cache the Johnson transform net. Accept bytes (uploaded) or a local path.\n",
    "    Returns a model on the requested device in eval() mode.\n",
    "    \"\"\"\n",
    "    device = torch.device(device_str)\n",
    "    net = TransformNet().to(device)\n",
    "\n",
    "    # Resolve checkpoint\n",
    "    if model_bytes is not None:\n",
    "        ckpt = torch.load(io.BytesIO(model_bytes), map_location=device)\n",
    "    elif model_path is not None and Path(model_path).exists():\n",
    "        ckpt = torch.load(model_path, map_location=device)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No valid Johnson .pth provided. Upload a file or enter a correct path.\")\n",
    "\n",
    "    # Some checkpoints save {'state_dict': ...} or have DataParallel 'module.' prefix\n",
    "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "        sd = ckpt[\"state_dict\"]\n",
    "    elif isinstance(ckpt, dict):\n",
    "        sd = ckpt\n",
    "    else:\n",
    "        # raw state_dict tensor map\n",
    "        sd = ckpt\n",
    "\n",
    "    cleaned = {}\n",
    "    for k, v in sd.items():\n",
    "        nk = k.replace('module.', '')\n",
    "        cleaned[nk] = v\n",
    "\n",
    "    missing, unexpected = net.load_state_dict(cleaned, strict=False)\n",
    "    if missing or unexpected:\n",
    "        st.warning(f\"Loaded with non-strict keys. Missing: {len(missing)} | Unexpected: {len(unexpected)}\")\n",
    "\n",
    "    net.eval()\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad_(False)\n",
    "    return net\n",
    "\n",
    "\n",
    "def pil_to_tensor(img: Image.Image, device: torch.device) -> torch.Tensor:\n",
    "    # Keep dynamic range [0,1]\n",
    "    arr = np.array(img).astype(np.float32) / 255.0\n",
    "    t = torch.from_numpy(arr).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "    return t\n",
    "\n",
    "\n",
    "def tensor_to_pil(t: torch.Tensor) -> Image.Image:\n",
    "    t = t.detach().clamp(0, 1).squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    t = (t * 255.0 + 0.5).astype(np.uint8)\n",
    "    return Image.fromarray(t)\n",
    "\n",
    "\n",
    "def resize_keep_ar(img: Image.Image, max_long_side: int) -> Image.Image:\n",
    "    w, h = img.size\n",
    "    if max(w, h) <= max_long_side:\n",
    "        return img\n",
    "    if w >= h:\n",
    "        new_w = max_long_side\n",
    "        new_h = int(round(h * (max_long_side / w)))\n",
    "    else:\n",
    "        new_h = max_long_side\n",
    "        new_w = int(round(w * (max_long_side / h)))\n",
    "    return img.resize((new_w, new_h), Image.BICUBIC)\n",
    "\n",
    "\n",
    "def stylize_pil(img: Image.Image, net: nn.Module, device: torch.device, use_fp16: bool = False) -> Image.Image:\n",
    "    with torch.no_grad():\n",
    "        x = pil_to_tensor(img, device)\n",
    "        if use_fp16 and device.type == 'cuda':\n",
    "            x = x.half()\n",
    "            net = net.half()\n",
    "        y = net(x)\n",
    "        return tensor_to_pil(y.float())\n",
    "\n",
    "\n",
    "# --------------------- UI ---------------------\n",
    "st.set_page_config(\n",
    "    page_title=\"Johnson Style Transfer UI\",\n",
    "    page_icon=\"🎨\",\n",
    "    layout=\"wide\",\n",
    ")\n",
    "\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <style>\n",
    "    .small-muted { color: var(--text-color-secondary); font-size: 0.9rem; }\n",
    "    .imgbox { border: 1px solid rgba(128,128,128,0.25); border-radius: 8px; padding: 6px; }\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "\n",
    "st.title(\"🎨 Johnson Neural Style Transfer (Inference UI)\")\n",
    "st.caption(\"Load a pre-trained Johnson transform network (.pth) and stylize images with ease.\")\n",
    "\n",
    "# Sidebar controls\n",
    "with st.sidebar:\n",
    "    st.header(\"Model & Runtime\")\n",
    "    device_auto = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device_choice = st.selectbox(\"Device\", [f\"auto ({device_auto})\", \"cuda\", \"cpu\"], index=0)\n",
    "    device_str = device_auto if device_choice.startswith(\"auto\") else device_choice\n",
    "\n",
    "    use_fp16 = st.checkbox(\"Use FP16 (faster on CUDA)\", value=(device_str == 'cuda'))\n",
    "\n",
    "    st.subheader(\"Johnson .pth\")\n",
    "    up = st.file_uploader(\"Upload Johnson checkpoint (.pth/.pt)\", type=[\"pth\", \"pt\"], accept_multiple_files=False)\n",
    "    model_path_text = st.text_input(\"...or path on server\", value=\"transform_net.pth\")\n",
    "\n",
    "    keep_size = st.checkbox(\"Keep original resolution\", value=True)\n",
    "    max_side = st.slider(\"Max long side (if resizing)\", 256, 2048, 1024, step=64)\n",
    "\n",
    "    out_fmt = st.selectbox(\"Output format\", [\"PNG\", \"JPEG\"], index=0)\n",
    "    jpeg_q =  st.slider(\"JPEG quality\", 70, 100, 95) if out_fmt == \"JPEG\" else None\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"**Tip**: For large photos, enable FP16 on CUDA and disable 'Keep original' if you hit memory limits.\")\n",
    "\n",
    "# Resolve model once per run\n",
    "model_bytes = up.read() if up is not None else None\n",
    "\n",
    "# Use cached loader\n",
    "try:\n",
    "    net = load_model(model_bytes, model_path_text if model_bytes is None else None, device_str)\n",
    "    device = next(net.parameters()).device\n",
    "except Exception as e:\n",
    "    st.error(f\"Model load error: {e}\")\n",
    "    net = None\n",
    "    device = torch.device(device_str)\n",
    "\n",
    "# Content images\n",
    "st.subheader(\"1) Upload content image(s)\")\n",
    "files = st.file_uploader(\"Images to stylize\", type=[\"jpg\",\"jpeg\",\"png\",\"bmp\",\"webp\"], accept_multiple_files=True)\n",
    "\n",
    "col_l, col_r = st.columns(2)\n",
    "\n",
    "if files:\n",
    "    # Preview first image\n",
    "    with col_l:\n",
    "        st.write(\"**Original (first)**\")\n",
    "        raw = Image.open(files[0]).convert(\"RGB\")\n",
    "        raw = ImageOps.exif_transpose(raw)\n",
    "        st.image(raw, use_column_width=True, output_format='PNG', clamp=True)\n",
    "\n",
    "    run_btn = st.button(\"✨ Stylize\", type='primary', use_container_width=True)\n",
    "    results: list[tuple[str, Image.Image]] = []\n",
    "\n",
    "    if run_btn and net is not None:\n",
    "        t0 = time.time()\n",
    "        bar = st.progress(0, text=\"Stylizing...\")\n",
    "        for i, f in enumerate(files, start=1):\n",
    "            img = Image.open(f).convert(\"RGB\")\n",
    "            img = ImageOps.exif_transpose(img)\n",
    "            if not keep_size:\n",
    "                img = resize_keep_ar(img, max_side)\n",
    "            out = stylize_pil(img, net, device, use_fp16=use_fp16)\n",
    "            results.append((f.name, out))\n",
    "            bar.progress(i/len(files), text=f\"Stylized {i}/{len(files)}\")\n",
    "        bar.empty()\n",
    "        st.success(f\"Done in {time.time()-t0:.2f}s for {len(files)} image(s).\")\n",
    "\n",
    "    if results:\n",
    "        # Show first result side-by-side\n",
    "        with col_r:\n",
    "            st.write(\"**Stylized (first)**\")\n",
    "            st.image(results[0][1], use_column_width=True, output_format='PNG', clamp=True)\n",
    "\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"2) Download\")\n",
    "        # Single or zip\n",
    "        if len(results) == 1:\n",
    "            name, im = results[0]\n",
    "            buf = io.BytesIO()\n",
    "            save_name = Path(name).stem + (\".png\" if out_fmt==\"PNG\" else \".jpg\")\n",
    "            if out_fmt == \"PNG\":\n",
    "                im.save(buf, format='PNG')\n",
    "            else:\n",
    "                im.save(buf, format='JPEG', quality=jpeg_q, optimize=True)\n",
    "            st.download_button(\n",
    "                label=f\"Download {save_name}\",\n",
    "                data=buf.getvalue(),\n",
    "                file_name=save_name,\n",
    "                mime='image/png' if out_fmt==\"PNG\" else 'image/jpeg',\n",
    "                use_container_width=True,\n",
    "            )\n",
    "        else:\n",
    "            # zip many\n",
    "            zip_buf = io.BytesIO()\n",
    "            with zipfile.ZipFile(zip_buf, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "                for name, im in results:\n",
    "                    out_name = Path(name).stem + (\".png\" if out_fmt==\"PNG\" else \".jpg\")\n",
    "                    b = io.BytesIO()\n",
    "                    if out_fmt == \"PNG\":\n",
    "                        im.save(b, format='PNG')\n",
    "                    else:\n",
    "                        im.save(b, format='JPEG', quality=jpeg_q, optimize=True)\n",
    "                    zf.writestr(out_name, b.getvalue())\n",
    "            st.download_button(\n",
    "                label=f\"Download {len(results)} images (zip)\",\n",
    "                data=zip_buf.getvalue(),\n",
    "                file_name=\"stylized_batch.zip\",\n",
    "                mime=\"application/zip\",\n",
    "                use_container_width=True,\n",
    "            )\n",
    "else:\n",
    "    st.info(\"Upload one or more content images to get started.\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.caption(\"Next: we can add an AdaIN tab and optional per-style training controls. 💡\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84e29c-b0d4-409c-a3e5-e10f6c7f3c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
