{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3962e647-9b82-4c31-be4f-46b71e8eaa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#Adain Hyper Parameter\n",
    "import sys, os, platform, subprocess, shutil\n",
    "import os, math, random, time, json, glob\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models, utils\n",
    "\n",
    "# Force CPU for now so everything runs\n",
    "USE_CPU_FOR_NOW = True\n",
    "\n",
    "import torch\n",
    "device = torch.device('cpu' if USE_CPU_FOR_NOW else ('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcaacea3-cf9a-46d5-a84c-07e270b8bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CPU_FOR_NOW = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec49fc38-09db-4585-8c85-6a4b80f6c7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "CFG: {'alpha': 1.0, 'batch_size': 8, 'content_dir': '/workspace/content', 'data_root': '/workspace', 'image_size_crop': 256, 'lambda_content': 0.5, 'lambda_style': 10.0, 'log_every': 200, 'lr': 0.0001, 'max_iterations': 80000, 'num_workers': 2, 'out_dir': './Folder/adain_runs3', 'resize_shorter_to': 512, 'resume': None, 'save_every': 5000, 'style_dir': '/workspace/style'}\n",
      "content_dir exists: True n_images: 49981\n",
      "style_dir   exists: True n_images: 49981\n",
      "example content: /workspace/content/000000000045.jpg\n",
      "example style  : /workspace/style/1.jpg\n",
      "Dataset size: 49981 Batches/epoch (approx): 6247\n",
      "\n",
      "=== RUN c1_s0.5_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 0.5, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=10.7049  Lc=8.5227  Ls=4.3644\n",
      "[   400/10000] loss=7.4854  Lc=6.0294  Ls=2.9120\n",
      "[   600/10000] loss=9.6542  Lc=7.6899  Ls=3.9287\n",
      "[   800/10000] loss=9.8296  Lc=8.1587  Ls=3.3418\n",
      "[  1000/10000] loss=9.7106  Lc=8.0580  Ls=3.3053\n",
      "[  1200/10000] loss=9.1555  Lc=7.5216  Ls=3.2677\n",
      "[  1400/10000] loss=6.3676  Lc=5.2316  Ls=2.2720\n",
      "[  1600/10000] loss=5.9050  Lc=4.9767  Ls=1.8566\n",
      "[  1800/10000] loss=8.5245  Lc=7.0024  Ls=3.0442\n",
      "[  2000/10000] loss=10.4512  Lc=8.4822  Ls=3.9381\n",
      "[  2200/10000] loss=6.1239  Lc=5.0091  Ls=2.2297\n",
      "[  2400/10000] loss=5.5472  Lc=4.5394  Ls=2.0157\n",
      "[  2600/10000] loss=6.4240  Lc=5.1991  Ls=2.4499\n",
      "[  2800/10000] loss=7.0370  Lc=5.7017  Ls=2.6706\n",
      "[  3000/10000] loss=5.8118  Lc=4.6046  Ls=2.4143\n",
      "[  3200/10000] loss=7.0830  Lc=6.0369  Ls=2.0921\n",
      "[  3400/10000] loss=7.8983  Lc=6.4130  Ls=2.9706\n",
      "[  3600/10000] loss=6.1650  Lc=5.1891  Ls=1.9519\n",
      "[  3800/10000] loss=4.2586  Lc=3.4173  Ls=1.6826\n",
      "[  4000/10000] loss=6.1795  Lc=5.0635  Ls=2.2321\n",
      "[  4200/10000] loss=6.4206  Lc=5.1161  Ls=2.6088\n",
      "[  4400/10000] loss=6.5523  Lc=5.3990  Ls=2.3066\n",
      "[  4600/10000] loss=5.1257  Lc=4.1889  Ls=1.8735\n",
      "[  4800/10000] loss=8.3547  Lc=6.8866  Ls=2.9363\n",
      "[  5000/10000] loss=5.8140  Lc=4.6784  Ls=2.2713\n",
      "[  5200/10000] loss=6.7777  Lc=5.4639  Ls=2.6275\n",
      "[  5400/10000] loss=6.2037  Lc=5.1440  Ls=2.1195\n",
      "[  5600/10000] loss=5.7382  Lc=4.8303  Ls=1.8158\n",
      "[  5800/10000] loss=6.3743  Lc=5.2551  Ls=2.2385\n",
      "[  6000/10000] loss=5.6277  Lc=4.5765  Ls=2.1023\n",
      "[  6200/10000] loss=6.8339  Lc=5.5930  Ls=2.4819\n",
      "[  6400/10000] loss=5.1172  Lc=4.0867  Ls=2.0610\n",
      "[  6600/10000] loss=6.5654  Lc=5.3208  Ls=2.4893\n",
      "[  6800/10000] loss=4.0603  Lc=3.3401  Ls=1.4404\n",
      "[  7000/10000] loss=5.7138  Lc=4.7141  Ls=1.9994\n",
      "[  7200/10000] loss=5.3265  Lc=4.3462  Ls=1.9606\n",
      "[  7400/10000] loss=6.9066  Lc=5.6562  Ls=2.5007\n",
      "[  7600/10000] loss=5.2401  Lc=4.2789  Ls=1.9223\n",
      "[  7800/10000] loss=4.0543  Lc=3.3965  Ls=1.3155\n",
      "[  8000/10000] loss=8.5372  Lc=6.5632  Ls=3.9482\n",
      "[  8200/10000] loss=5.2218  Lc=4.2486  Ls=1.9463\n",
      "[  8400/10000] loss=6.2102  Lc=4.8920  Ls=2.6365\n",
      "[  8600/10000] loss=5.7659  Lc=4.8130  Ls=1.9058\n",
      "[  8800/10000] loss=5.4419  Lc=4.5603  Ls=1.7633\n",
      "[  9000/10000] loss=6.6009  Lc=5.3064  Ls=2.5891\n",
      "[  9200/10000] loss=6.4610  Lc=5.2142  Ls=2.4937\n",
      "[  9400/10000] loss=6.5668  Lc=5.2230  Ls=2.6876\n",
      "[  9600/10000] loss=4.7315  Lc=3.9158  Ls=1.6313\n",
      "[  9800/10000] loss=4.6963  Lc=3.7278  Ls=1.9370\n",
      "[ 10000/10000] loss=12.9824  Lc=9.7002  Ls=6.5643\n",
      "[final] saved: ./Folder/adain_runs3/c1_s0.5_a1_it10000/decoder_final3.pth\n",
      "\n",
      "=== RUN c1_s1_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 1.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=13.2791  Lc=10.0613  Ls=3.2178\n",
      "[   400/10000] loss=10.0662  Lc=7.4369  Ls=2.6293\n",
      "[   600/10000] loss=15.2278  Lc=10.8195  Ls=4.4083\n",
      "[   800/10000] loss=8.2162  Lc=5.8963  Ls=2.3199\n",
      "[  1000/10000] loss=9.8220  Lc=7.4363  Ls=2.3857\n",
      "[  1200/10000] loss=10.0615  Lc=7.4218  Ls=2.6397\n",
      "[  1400/10000] loss=9.6357  Lc=6.8852  Ls=2.7505\n",
      "[  1600/10000] loss=7.5619  Lc=5.7641  Ls=1.7979\n",
      "[  1800/10000] loss=9.3457  Lc=6.9507  Ls=2.3950\n",
      "[  2000/10000] loss=7.1417  Lc=5.5703  Ls=1.5715\n",
      "[  2200/10000] loss=6.7966  Lc=5.2138  Ls=1.5828\n",
      "[  2400/10000] loss=7.8233  Lc=5.6260  Ls=2.1973\n",
      "[  2600/10000] loss=6.2438  Lc=4.4662  Ls=1.7776\n",
      "[  2800/10000] loss=6.2561  Lc=4.7488  Ls=1.5073\n",
      "[  3000/10000] loss=8.3037  Lc=6.5949  Ls=1.7088\n",
      "[  3200/10000] loss=9.0015  Lc=6.2054  Ls=2.7961\n",
      "[  3400/10000] loss=6.7135  Lc=5.0999  Ls=1.6136\n",
      "[  3600/10000] loss=5.5417  Lc=4.3123  Ls=1.2294\n",
      "[  3800/10000] loss=7.5616  Lc=5.8754  Ls=1.6861\n",
      "[  4000/10000] loss=5.7043  Lc=4.4169  Ls=1.2874\n",
      "[  4200/10000] loss=8.3277  Lc=6.0863  Ls=2.2413\n",
      "[  4400/10000] loss=7.5815  Lc=5.6324  Ls=1.9491\n",
      "[  4600/10000] loss=7.0338  Lc=5.3083  Ls=1.7255\n",
      "[  4800/10000] loss=5.4307  Lc=4.0589  Ls=1.3718\n",
      "[  5000/10000] loss=6.2937  Lc=4.9031  Ls=1.3906\n",
      "[  5200/10000] loss=6.0948  Lc=4.7189  Ls=1.3759\n",
      "[  5400/10000] loss=6.3420  Lc=4.5778  Ls=1.7642\n",
      "[  5600/10000] loss=8.5275  Lc=5.5850  Ls=2.9425\n",
      "[  5800/10000] loss=6.5202  Lc=4.9585  Ls=1.5617\n",
      "[  6000/10000] loss=11.3746  Lc=8.0198  Ls=3.3548\n",
      "[  6200/10000] loss=6.0181  Lc=4.4974  Ls=1.5207\n",
      "[  6400/10000] loss=6.3647  Lc=4.6142  Ls=1.7504\n",
      "[  6600/10000] loss=8.5211  Lc=6.1532  Ls=2.3679\n",
      "[  6800/10000] loss=6.3130  Lc=4.8548  Ls=1.4581\n",
      "[  7000/10000] loss=4.9347  Lc=3.7770  Ls=1.1577\n",
      "[  7200/10000] loss=6.4544  Lc=5.0048  Ls=1.4496\n",
      "[  7400/10000] loss=10.0558  Lc=7.2990  Ls=2.7567\n",
      "[  7600/10000] loss=4.9997  Lc=3.3908  Ls=1.6089\n",
      "[  7800/10000] loss=5.7822  Lc=4.2903  Ls=1.4920\n",
      "[  8000/10000] loss=7.2118  Lc=5.4074  Ls=1.8044\n",
      "[  8200/10000] loss=5.5730  Lc=4.0028  Ls=1.5702\n",
      "[  8400/10000] loss=8.9625  Lc=6.8390  Ls=2.1235\n",
      "[  8600/10000] loss=7.9669  Lc=5.8712  Ls=2.0957\n",
      "[  8800/10000] loss=5.9734  Lc=4.5877  Ls=1.3857\n",
      "[  9000/10000] loss=6.3025  Lc=4.9487  Ls=1.3538\n",
      "[  9200/10000] loss=6.2633  Lc=4.6247  Ls=1.6386\n",
      "[  9400/10000] loss=7.0769  Lc=5.2344  Ls=1.8425\n",
      "[  9600/10000] loss=7.5996  Lc=5.8170  Ls=1.7826\n",
      "[  9800/10000] loss=6.7820  Lc=5.2890  Ls=1.4930\n",
      "[ 10000/10000] loss=5.5450  Lc=4.1721  Ls=1.3729\n",
      "[final] saved: ./Folder/adain_runs3/c1_s1_a1_it10000/decoder_final3.pth\n",
      "\n",
      "=== RUN c1_s2_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 2.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=19.8137  Lc=11.4217  Ls=4.1960\n",
      "[   400/10000] loss=17.7353  Lc=11.9549  Ls=2.8902\n",
      "[   600/10000] loss=15.8512  Lc=10.7389  Ls=2.5561\n",
      "[   800/10000] loss=12.4517  Lc=8.2874  Ls=2.0822\n",
      "[  1000/10000] loss=10.0215  Lc=6.9415  Ls=1.5400\n",
      "[  1200/10000] loss=15.5162  Lc=8.9962  Ls=3.2600\n",
      "[  1400/10000] loss=13.3117  Lc=8.7205  Ls=2.2956\n",
      "[  1600/10000] loss=11.4366  Lc=7.6835  Ls=1.8766\n",
      "[  1800/10000] loss=10.5684  Lc=7.4631  Ls=1.5527\n",
      "[  2000/10000] loss=10.5591  Lc=7.3982  Ls=1.5804\n",
      "[  2200/10000] loss=7.5561  Lc=5.3960  Ls=1.0801\n",
      "[  2400/10000] loss=9.2486  Lc=6.4502  Ls=1.3992\n",
      "[  2600/10000] loss=7.6959  Lc=5.0985  Ls=1.2987\n",
      "[  2800/10000] loss=7.5971  Lc=5.3154  Ls=1.1409\n",
      "[  3000/10000] loss=10.9532  Lc=7.3995  Ls=1.7768\n",
      "[  3200/10000] loss=7.3767  Lc=5.1053  Ls=1.1357\n",
      "[  3400/10000] loss=11.7129  Lc=7.6039  Ls=2.0545\n",
      "[  3600/10000] loss=8.9747  Lc=5.5877  Ls=1.6935\n",
      "[  3800/10000] loss=7.1802  Lc=4.9328  Ls=1.1237\n",
      "[  4000/10000] loss=8.1577  Lc=5.1917  Ls=1.4830\n",
      "[  4200/10000] loss=12.7564  Lc=7.8044  Ls=2.4760\n",
      "[  4400/10000] loss=6.5347  Lc=4.6056  Ls=0.9646\n",
      "[  4600/10000] loss=9.3380  Lc=6.7126  Ls=1.3127\n",
      "[  4800/10000] loss=9.0047  Lc=5.9651  Ls=1.5198\n",
      "[  5000/10000] loss=7.0205  Lc=4.8118  Ls=1.1044\n",
      "[  5200/10000] loss=7.6508  Lc=4.9152  Ls=1.3678\n",
      "[  5400/10000] loss=8.4388  Lc=5.8856  Ls=1.2766\n",
      "[  5600/10000] loss=13.6577  Lc=8.8020  Ls=2.4278\n",
      "[  5800/10000] loss=7.6761  Lc=5.3861  Ls=1.1450\n",
      "[  6000/10000] loss=10.7848  Lc=7.1249  Ls=1.8299\n",
      "[  6200/10000] loss=9.4038  Lc=6.3684  Ls=1.5177\n",
      "[  6400/10000] loss=8.2573  Lc=5.7446  Ls=1.2563\n",
      "[  6600/10000] loss=7.9557  Lc=5.6380  Ls=1.1588\n",
      "[  6800/10000] loss=8.2769  Lc=5.2924  Ls=1.4922\n",
      "[  7000/10000] loss=11.2716  Lc=7.0140  Ls=2.1288\n",
      "[  7200/10000] loss=7.4672  Lc=5.0498  Ls=1.2087\n",
      "[  7400/10000] loss=9.8904  Lc=6.6360  Ls=1.6272\n",
      "[  7600/10000] loss=10.6020  Lc=6.1631  Ls=2.2195\n",
      "[  7800/10000] loss=9.8131  Lc=6.6725  Ls=1.5703\n",
      "[  8000/10000] loss=8.4572  Lc=6.0552  Ls=1.2010\n",
      "[  8200/10000] loss=5.3376  Lc=3.6978  Ls=0.8199\n",
      "[  8400/10000] loss=8.8945  Lc=5.9587  Ls=1.4679\n",
      "[  8600/10000] loss=15.3326  Lc=8.9083  Ls=3.2122\n",
      "[  8800/10000] loss=7.6669  Lc=4.6949  Ls=1.4860\n",
      "[  9000/10000] loss=8.2173  Lc=5.7763  Ls=1.2205\n",
      "[  9200/10000] loss=9.4048  Lc=6.1532  Ls=1.6258\n",
      "[  9400/10000] loss=7.0476  Lc=4.6514  Ls=1.1981\n",
      "[  9600/10000] loss=9.5987  Lc=6.2745  Ls=1.6621\n",
      "[  9800/10000] loss=9.7460  Lc=6.8545  Ls=1.4458\n",
      "[ 10000/10000] loss=6.6520  Lc=4.4680  Ls=1.0920\n",
      "[final] saved: ./Folder/adain_runs3/c1_s2_a1_it10000/decoder_final3.pth\n",
      "\n",
      "=== RUN c1_s5_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 5.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=28.4788  Lc=13.1946  Ls=3.0568\n",
      "[   400/10000] loss=21.3828  Lc=9.8325  Ls=2.3100\n",
      "[   600/10000] loss=20.9109  Lc=10.1481  Ls=2.1526\n",
      "[   800/10000] loss=22.0349  Lc=11.5505  Ls=2.0969\n",
      "[  1000/10000] loss=28.6345  Lc=12.6199  Ls=3.2029\n",
      "[  1200/10000] loss=24.1145  Lc=11.5122  Ls=2.5205\n",
      "[  1400/10000] loss=20.7424  Lc=11.0350  Ls=1.9415\n",
      "[  1600/10000] loss=20.1735  Lc=9.7281  Ls=2.0891\n",
      "[  1800/10000] loss=16.2031  Lc=9.6002  Ls=1.3206\n",
      "[  2000/10000] loss=15.2553  Lc=8.9140  Ls=1.2682\n",
      "[  2200/10000] loss=21.2317  Lc=12.0516  Ls=1.8360\n",
      "[  2400/10000] loss=12.8943  Lc=7.1077  Ls=1.1573\n",
      "[  2600/10000] loss=22.6094  Lc=11.6816  Ls=2.1856\n",
      "[  2800/10000] loss=16.7791  Lc=8.8068  Ls=1.5945\n",
      "[  3000/10000] loss=16.7499  Lc=8.7136  Ls=1.6072\n",
      "[  3200/10000] loss=21.0847  Lc=11.5073  Ls=1.9155\n",
      "[  3400/10000] loss=20.8685  Lc=10.2012  Ls=2.1335\n",
      "[  3600/10000] loss=14.3207  Lc=7.8555  Ls=1.2930\n",
      "[  3800/10000] loss=19.7613  Lc=10.7524  Ls=1.8018\n",
      "[  4000/10000] loss=14.5034  Lc=7.4435  Ls=1.4120\n",
      "[  4200/10000] loss=12.2312  Lc=6.8426  Ls=1.0777\n",
      "[  4400/10000] loss=14.1160  Lc=7.9558  Ls=1.2320\n",
      "[  4600/10000] loss=14.6173  Lc=8.3204  Ls=1.2594\n",
      "[  4800/10000] loss=17.1668  Lc=8.5456  Ls=1.7242\n",
      "[  5000/10000] loss=18.4386  Lc=10.3933  Ls=1.6091\n",
      "[  5200/10000] loss=7.9452  Lc=4.6890  Ls=0.6512\n",
      "[  5400/10000] loss=11.5459  Lc=6.1076  Ls=1.0876\n",
      "[  5600/10000] loss=19.1108  Lc=9.8285  Ls=1.8565\n",
      "[  5800/10000] loss=10.4381  Lc=5.6794  Ls=0.9517\n",
      "[  6000/10000] loss=12.4655  Lc=7.2658  Ls=1.0399\n",
      "[  6200/10000] loss=15.7815  Lc=7.5474  Ls=1.6468\n",
      "[  6400/10000] loss=13.5764  Lc=7.9035  Ls=1.1346\n",
      "[  6600/10000] loss=13.6980  Lc=6.7598  Ls=1.3876\n",
      "[  6800/10000] loss=15.8734  Lc=8.3809  Ls=1.4985\n",
      "[  7000/10000] loss=18.6143  Lc=10.7103  Ls=1.5808\n",
      "[  7200/10000] loss=11.4753  Lc=6.9049  Ls=0.9141\n",
      "[  7400/10000] loss=19.5333  Lc=10.7478  Ls=1.7571\n",
      "[  7600/10000] loss=10.8244  Lc=5.3885  Ls=1.0872\n",
      "[  7800/10000] loss=12.3599  Lc=7.2053  Ls=1.0309\n",
      "[  8000/10000] loss=16.2170  Lc=9.5702  Ls=1.3293\n",
      "[  8200/10000] loss=15.0283  Lc=7.8487  Ls=1.4359\n",
      "[  8400/10000] loss=10.1282  Lc=5.6746  Ls=0.8907\n",
      "[  8600/10000] loss=14.9628  Lc=8.2621  Ls=1.3401\n",
      "[  8800/10000] loss=12.8595  Lc=6.7618  Ls=1.2196\n",
      "[  9000/10000] loss=10.7788  Lc=6.3868  Ls=0.8784\n",
      "[  9200/10000] loss=21.3760  Lc=10.1939  Ls=2.2364\n",
      "[  9400/10000] loss=11.8245  Lc=6.9893  Ls=0.9670\n",
      "[  9600/10000] loss=17.2071  Lc=9.3198  Ls=1.5775\n",
      "[  9800/10000] loss=9.6362  Lc=5.4529  Ls=0.8367\n",
      "[ 10000/10000] loss=11.0595  Lc=6.5065  Ls=0.9106\n",
      "[final] saved: ./Folder/adain_runs3/c1_s5_a1_it10000/decoder_final3.pth\n",
      "\n",
      "=== RUN c1_s10_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 10.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=42.4682  Lc=13.0310  Ls=2.9437\n",
      "[   400/10000] loss=51.2218  Lc=13.0631  Ls=3.8159\n",
      "[   600/10000] loss=32.9503  Lc=11.4737  Ls=2.1477\n",
      "[   800/10000] loss=32.3980  Lc=11.2991  Ls=2.1099\n",
      "[  1000/10000] loss=21.1357  Lc=9.5400  Ls=1.1596\n",
      "[  1200/10000] loss=48.1683  Lc=15.2669  Ls=3.2901\n",
      "[  1400/10000] loss=33.4732  Lc=13.1886  Ls=2.0285\n",
      "[  1600/10000] loss=18.0184  Lc=7.7418  Ls=1.0277\n",
      "[  1800/10000] loss=32.1845  Lc=12.1273  Ls=2.0057\n",
      "[  2000/10000] loss=40.2671  Lc=11.9532  Ls=2.8314\n",
      "[  2200/10000] loss=32.8559  Lc=12.3246  Ls=2.0531\n",
      "[  2400/10000] loss=20.3767  Lc=8.2546  Ls=1.2122\n",
      "[  2600/10000] loss=17.3921  Lc=7.6580  Ls=0.9734\n",
      "[  2800/10000] loss=40.1110  Lc=13.8521  Ls=2.6259\n",
      "[  3000/10000] loss=22.4595  Lc=9.7603  Ls=1.2699\n",
      "[  3200/10000] loss=22.8070  Lc=8.4070  Ls=1.4400\n",
      "[  3400/10000] loss=23.3132  Lc=11.1062  Ls=1.2207\n",
      "[  3600/10000] loss=18.7615  Lc=8.5341  Ls=1.0227\n",
      "[  3800/10000] loss=19.4301  Lc=8.3159  Ls=1.1114\n",
      "[  4000/10000] loss=28.0758  Lc=13.0451  Ls=1.5031\n",
      "[  4200/10000] loss=23.1896  Lc=8.9272  Ls=1.4262\n",
      "[  4400/10000] loss=23.2153  Lc=10.6880  Ls=1.2527\n",
      "[  4600/10000] loss=46.0827  Lc=17.7243  Ls=2.8358\n",
      "[  4800/10000] loss=22.5224  Lc=10.6580  Ls=1.1864\n",
      "[  5000/10000] loss=30.2625  Lc=12.0195  Ls=1.8243\n",
      "[  5200/10000] loss=30.3878  Lc=9.8211  Ls=2.0567\n",
      "[  5400/10000] loss=17.7955  Lc=8.5851  Ls=0.9210\n",
      "[  5600/10000] loss=22.4003  Lc=7.8148  Ls=1.4586\n",
      "[  5800/10000] loss=27.5722  Lc=13.1028  Ls=1.4469\n",
      "[  6000/10000] loss=19.2135  Lc=7.7371  Ls=1.1476\n",
      "[  6200/10000] loss=16.6281  Lc=7.1005  Ls=0.9528\n",
      "[  6400/10000] loss=23.7814  Lc=11.0491  Ls=1.2732\n",
      "[  6600/10000] loss=30.6165  Lc=12.2635  Ls=1.8353\n",
      "[  6800/10000] loss=25.9889  Lc=11.6571  Ls=1.4332\n",
      "[  7000/10000] loss=19.8818  Lc=9.3959  Ls=1.0486\n",
      "[  7200/10000] loss=24.7508  Lc=11.5956  Ls=1.3155\n",
      "[  7400/10000] loss=25.8157  Lc=11.6403  Ls=1.4175\n",
      "[  7600/10000] loss=21.3559  Lc=8.5227  Ls=1.2833\n",
      "[  7800/10000] loss=16.5131  Lc=8.1782  Ls=0.8335\n",
      "[  8000/10000] loss=26.5140  Lc=12.2371  Ls=1.4277\n",
      "[  8200/10000] loss=19.1057  Lc=8.8628  Ls=1.0243\n",
      "[  8400/10000] loss=17.2902  Lc=8.0182  Ls=0.9272\n",
      "[  8600/10000] loss=29.1179  Lc=13.6354  Ls=1.5483\n",
      "[  8800/10000] loss=18.3152  Lc=8.2681  Ls=1.0047\n",
      "[  9000/10000] loss=18.1779  Lc=8.3038  Ls=0.9874\n",
      "[  9200/10000] loss=20.0876  Lc=8.9446  Ls=1.1143\n",
      "[  9400/10000] loss=16.3213  Lc=7.3331  Ls=0.8988\n",
      "[  9600/10000] loss=16.9431  Lc=7.4326  Ls=0.9511\n",
      "[  9800/10000] loss=18.5005  Lc=9.4230  Ls=0.9078\n",
      "[ 10000/10000] loss=17.8825  Lc=8.9383  Ls=0.8944\n",
      "[final] saved: ./Folder/adain_runs3/c1_s10_a1_it10000/decoder_final3.pth\n",
      "\n",
      "=== RUN c1_s20_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 20.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=87.9482  Lc=18.1393  Ls=3.4904\n",
      "[   400/10000] loss=58.5074  Lc=13.6330  Ls=2.2437\n",
      "[   600/10000] loss=61.0616  Lc=11.8698  Ls=2.4596\n",
      "[   800/10000] loss=92.4383  Lc=15.9877  Ls=3.8225\n",
      "[  1000/10000] loss=63.9863  Lc=14.8672  Ls=2.4560\n",
      "[  1200/10000] loss=42.3041  Lc=10.5691  Ls=1.5867\n",
      "[  1400/10000] loss=31.3971  Lc=9.9158  Ls=1.0741\n",
      "[  1600/10000] loss=83.0091  Lc=19.8887  Ls=3.1560\n",
      "[  1800/10000] loss=48.2763  Lc=13.4742  Ls=1.7401\n",
      "[  2000/10000] loss=36.2214  Lc=11.8496  Ls=1.2186\n",
      "[  2200/10000] loss=43.1646  Lc=12.7018  Ls=1.5231\n",
      "[  2400/10000] loss=42.0038  Lc=11.6804  Ls=1.5162\n",
      "[  2600/10000] loss=45.7587  Lc=14.1364  Ls=1.5811\n",
      "[  2800/10000] loss=43.4406  Lc=14.1867  Ls=1.4627\n",
      "[  3000/10000] loss=58.2356  Lc=13.1684  Ls=2.2534\n",
      "[  3200/10000] loss=61.6305  Lc=14.3851  Ls=2.3623\n",
      "[  3400/10000] loss=38.8237  Lc=13.1570  Ls=1.2833\n",
      "[  3600/10000] loss=35.4158  Lc=10.7100  Ls=1.2353\n",
      "[  3800/10000] loss=33.7230  Lc=11.6980  Ls=1.1012\n",
      "[  4000/10000] loss=34.2396  Lc=11.0379  Ls=1.1601\n",
      "[  4200/10000] loss=46.1736  Lc=14.5423  Ls=1.5816\n",
      "[  4400/10000] loss=42.7614  Lc=14.7965  Ls=1.3982\n",
      "[  4600/10000] loss=28.8478  Lc=7.8723  Ls=1.0488\n",
      "[  4800/10000] loss=46.4278  Lc=15.1513  Ls=1.5638\n",
      "[  5000/10000] loss=49.3890  Lc=13.0105  Ls=1.8189\n",
      "[  5200/10000] loss=33.4473  Lc=8.6131  Ls=1.2417\n",
      "[  5400/10000] loss=49.0936  Lc=12.9308  Ls=1.8081\n",
      "[  5600/10000] loss=52.2789  Lc=16.9237  Ls=1.7678\n",
      "[  5800/10000] loss=30.8344  Lc=9.6100  Ls=1.0612\n",
      "[  6000/10000] loss=46.3480  Lc=16.1423  Ls=1.5103\n",
      "[  6200/10000] loss=38.7451  Lc=12.6091  Ls=1.3068\n",
      "[  6400/10000] loss=38.8486  Lc=11.9935  Ls=1.3428\n",
      "[  6600/10000] loss=66.3916  Lc=19.7767  Ls=2.3307\n",
      "[  6800/10000] loss=24.1716  Lc=8.9278  Ls=0.7622\n",
      "[  7000/10000] loss=30.7646  Lc=10.2802  Ls=1.0242\n",
      "[  7200/10000] loss=26.9987  Lc=8.5415  Ls=0.9229\n",
      "[  7400/10000] loss=39.7576  Lc=14.0950  Ls=1.2831\n",
      "[  7600/10000] loss=33.6927  Lc=9.9389  Ls=1.1877\n",
      "[  7800/10000] loss=43.0766  Lc=15.3030  Ls=1.3887\n",
      "[  8000/10000] loss=27.3765  Lc=9.7999  Ls=0.8788\n",
      "[  8200/10000] loss=38.6348  Lc=12.0608  Ls=1.3287\n",
      "[  8400/10000] loss=43.3640  Lc=9.2040  Ls=1.7080\n",
      "[  8600/10000] loss=31.2458  Lc=11.7341  Ls=0.9756\n",
      "[  8800/10000] loss=31.2912  Lc=11.2796  Ls=1.0006\n",
      "[  9000/10000] loss=32.3299  Lc=9.8741  Ls=1.1228\n",
      "[  9200/10000] loss=25.5762  Lc=8.5181  Ls=0.8529\n",
      "[  9400/10000] loss=35.1770  Lc=12.1334  Ls=1.1522\n",
      "[  9600/10000] loss=24.4814  Lc=7.8242  Ls=0.8329\n",
      "[  9800/10000] loss=43.8180  Lc=15.5204  Ls=1.4149\n",
      "[ 10000/10000] loss=36.3624  Lc=10.7952  Ls=1.2784\n",
      "[final] saved: ./Folder/adain_runs3/c1_s20_a1_it10000/decoder_final3.pth\n",
      "\n",
      "=== RUN c0.5_s5_a1_it10000 ===\n",
      "{'lambda_content': 0.5, 'lambda_style': 5.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=20.0574  Lc=11.4877  Ls=2.8627\n",
      "[   400/10000] loss=24.2851  Lc=11.9960  Ls=3.6574\n",
      "[   600/10000] loss=13.8402  Lc=9.9303  Ls=1.7750\n",
      "[   800/10000] loss=13.1838  Lc=9.0846  Ls=1.7283\n",
      "[  1000/10000] loss=15.0467  Lc=12.8524  Ls=1.7241\n",
      "[  1200/10000] loss=14.9988  Lc=10.9289  Ls=1.9069\n",
      "[  1400/10000] loss=12.8837  Lc=11.1316  Ls=1.4636\n",
      "[  1600/10000] loss=15.7885  Lc=11.4431  Ls=2.0134\n",
      "[  1800/10000] loss=16.5554  Lc=14.1063  Ls=1.9005\n",
      "[  2000/10000] loss=15.7779  Lc=11.5472  Ls=2.0009\n",
      "[  2200/10000] loss=11.1599  Lc=11.2604  Ls=1.1059\n",
      "[  2400/10000] loss=12.8964  Lc=11.4511  Ls=1.4342\n",
      "[  2600/10000] loss=21.5967  Lc=18.6354  Ls=2.4558\n",
      "[  2800/10000] loss=12.4121  Lc=10.9091  Ls=1.3915\n",
      "[  3000/10000] loss=13.1576  Lc=11.1867  Ls=1.5129\n",
      "[  3200/10000] loss=8.5745  Lc=6.9155  Ls=1.0234\n",
      "[  3400/10000] loss=21.5155  Lc=17.7999  Ls=2.5231\n",
      "[  3600/10000] loss=15.2814  Lc=13.4654  Ls=1.7097\n",
      "[  3800/10000] loss=16.3844  Lc=14.0392  Ls=1.8730\n",
      "[  4000/10000] loss=15.4668  Lc=13.0214  Ls=1.7912\n",
      "[  4200/10000] loss=8.6761  Lc=8.1916  Ls=0.9161\n",
      "[  4400/10000] loss=11.4746  Lc=10.0946  Ls=1.2855\n",
      "[  4600/10000] loss=11.7733  Lc=11.0800  Ls=1.2467\n",
      "[  4800/10000] loss=8.4055  Lc=7.2632  Ls=0.9548\n",
      "[  5000/10000] loss=11.7815  Lc=11.1227  Ls=1.2440\n",
      "[  5200/10000] loss=13.9206  Lc=12.3462  Ls=1.5495\n",
      "[  5400/10000] loss=10.1242  Lc=9.4636  Ls=1.0785\n",
      "[  5600/10000] loss=12.7697  Lc=11.9014  Ls=1.3638\n",
      "[  5800/10000] loss=10.2387  Lc=10.0146  Ls=1.0463\n",
      "[  6000/10000] loss=7.2487  Lc=7.1784  Ls=0.7319\n",
      "[  6200/10000] loss=14.9881  Lc=11.2315  Ls=1.8745\n",
      "[  6400/10000] loss=12.6330  Lc=10.5660  Ls=1.4700\n",
      "[  6600/10000] loss=9.7016  Lc=10.6289  Ls=0.8774\n",
      "[  6800/10000] loss=9.8671  Lc=8.8502  Ls=1.0884\n",
      "[  7000/10000] loss=11.0982  Lc=11.2631  Ls=1.0933\n",
      "[  7200/10000] loss=9.4445  Lc=8.7962  Ls=1.0093\n",
      "[  7400/10000] loss=8.9028  Lc=8.6131  Ls=0.9192\n",
      "[  7600/10000] loss=10.2495  Lc=8.5724  Ls=1.1926\n",
      "[  7800/10000] loss=10.4312  Lc=9.4624  Ls=1.1400\n",
      "[  8000/10000] loss=11.4953  Lc=10.1990  Ls=1.2792\n",
      "[  8200/10000] loss=9.1554  Lc=8.3682  Ls=0.9943\n",
      "[  8400/10000] loss=8.0848  Lc=7.4722  Ls=0.8697\n",
      "[  8600/10000] loss=8.2036  Lc=8.4030  Ls=0.8004\n",
      "[  8800/10000] loss=8.6720  Lc=8.4062  Ls=0.8938\n",
      "[  9000/10000] loss=12.2779  Lc=11.8220  Ls=1.2734\n",
      "[  9200/10000] loss=10.3920  Lc=7.3510  Ls=1.3433\n",
      "[  9400/10000] loss=7.4209  Lc=6.9378  Ls=0.7904\n",
      "[  9600/10000] loss=8.3571  Lc=7.5682  Ls=0.9146\n",
      "[  9800/10000] loss=10.1329  Lc=8.8786  Ls=1.1387\n",
      "[ 10000/10000] loss=10.5432  Lc=9.4408  Ls=1.1646\n",
      "[final] saved: ./Folder/adain_runs3/c0.5_s5_a1_it10000/decoder_final3.pth\n",
      "\n",
      "=== RUN c1_s5_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 5.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=29.9759  Lc=13.4428  Ls=3.3066\n",
      "[   400/10000] loss=29.9038  Lc=15.9658  Ls=2.7876\n",
      "[   600/10000] loss=25.0435  Lc=11.5895  Ls=2.6908\n",
      "[   800/10000] loss=31.0354  Lc=13.7755  Ls=3.4520\n",
      "[  1000/10000] loss=25.4880  Lc=11.6971  Ls=2.7582\n",
      "[  1200/10000] loss=20.5271  Lc=10.8597  Ls=1.9335\n",
      "[  1400/10000] loss=24.7403  Lc=12.1919  Ls=2.5097\n",
      "[  1600/10000] loss=20.1766  Lc=11.7065  Ls=1.6940\n",
      "[  1800/10000] loss=12.8799  Lc=7.2087  Ls=1.1342\n",
      "[  2000/10000] loss=17.8245  Lc=10.2782  Ls=1.5093\n",
      "[  2200/10000] loss=18.2181  Lc=9.6862  Ls=1.7064\n",
      "[  2400/10000] loss=14.1217  Lc=7.3995  Ls=1.3444\n",
      "[  2600/10000] loss=15.1375  Lc=8.1369  Ls=1.4001\n",
      "[  2800/10000] loss=16.9014  Lc=9.1895  Ls=1.5424\n",
      "[  3000/10000] loss=17.7258  Lc=9.1014  Ls=1.7249\n",
      "[  3200/10000] loss=21.1755  Lc=10.7574  Ls=2.0836\n",
      "[  3400/10000] loss=21.0960  Lc=10.8090  Ls=2.0574\n",
      "[  3600/10000] loss=12.1029  Lc=7.2726  Ls=0.9661\n",
      "[  3800/10000] loss=14.2328  Lc=8.0268  Ls=1.2412\n",
      "[  4000/10000] loss=14.9049  Lc=7.7353  Ls=1.4339\n",
      "[  4200/10000] loss=12.6142  Lc=7.2520  Ls=1.0724\n",
      "[  4400/10000] loss=15.5811  Lc=9.4045  Ls=1.2353\n",
      "[  4600/10000] loss=11.0218  Lc=6.1618  Ls=0.9720\n",
      "[  4800/10000] loss=14.9563  Lc=8.4691  Ls=1.2974\n",
      "[  5000/10000] loss=15.1107  Lc=8.3140  Ls=1.3593\n",
      "[  5200/10000] loss=12.4162  Lc=6.8425  Ls=1.1147\n",
      "[  5400/10000] loss=16.0371  Lc=8.4614  Ls=1.5151\n",
      "[  5600/10000] loss=11.9031  Lc=6.7333  Ls=1.0340\n",
      "[  5800/10000] loss=12.8225  Lc=7.5963  Ls=1.0452\n",
      "[  6000/10000] loss=23.1632  Lc=11.8978  Ls=2.2531\n",
      "[  6200/10000] loss=17.5541  Lc=8.4726  Ls=1.8163\n",
      "[  6400/10000] loss=11.3457  Lc=6.5155  Ls=0.9660\n",
      "[  6600/10000] loss=13.4014  Lc=7.1129  Ls=1.2577\n",
      "[  6800/10000] loss=11.9542  Lc=6.8649  Ls=1.0179\n",
      "[  7000/10000] loss=14.3346  Lc=8.4770  Ls=1.1715\n",
      "[  7200/10000] loss=12.6089  Lc=6.7141  Ls=1.1790\n",
      "[  7400/10000] loss=12.7799  Lc=7.0580  Ls=1.1444\n",
      "[  7600/10000] loss=17.0548  Lc=9.0938  Ls=1.5922\n",
      "[  7800/10000] loss=9.8635  Lc=5.6959  Ls=0.8335\n",
      "[  8000/10000] loss=13.1215  Lc=7.2930  Ls=1.1657\n",
      "[  8200/10000] loss=12.2057  Lc=6.6424  Ls=1.1127\n",
      "[  8400/10000] loss=15.9239  Lc=9.3410  Ls=1.3166\n",
      "[  8600/10000] loss=11.2764  Lc=6.7159  Ls=0.9121\n",
      "[  8800/10000] loss=15.5225  Lc=8.6989  Ls=1.3647\n",
      "[  9000/10000] loss=9.2081  Lc=5.5728  Ls=0.7271\n",
      "[  9200/10000] loss=10.1733  Lc=5.6110  Ls=0.9125\n",
      "[  9400/10000] loss=14.6871  Lc=7.9595  Ls=1.3455\n",
      "[  9600/10000] loss=11.3555  Lc=6.3671  Ls=0.9977\n",
      "[  9800/10000] loss=10.6143  Lc=6.1877  Ls=0.8853\n",
      "[ 10000/10000] loss=13.2941  Lc=8.0048  Ls=1.0579\n",
      "[final] saved: ./Folder/adain_runs3/c1_s5_a1_it10000/decoder_final3.pth\n",
      "\n",
      "=== RUN c2_s5_a1_it10000 ===\n",
      "{'lambda_content': 2.0, 'lambda_style': 5.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=47.7146  Lc=14.1107  Ls=3.8987\n",
      "[   400/10000] loss=41.1484  Lc=10.8911  Ls=3.8732\n",
      "[   600/10000] loss=26.2692  Lc=8.3476  Ls=1.9148\n",
      "[   800/10000] loss=28.6671  Lc=10.1002  Ls=1.6933\n",
      "[  1000/10000] loss=23.3068  Lc=7.4058  Ls=1.6990\n",
      "[  1200/10000] loss=22.6165  Lc=7.2731  Ls=1.6140\n",
      "[  1400/10000] loss=26.2012  Lc=8.6675  Ls=1.7732\n",
      "[  1600/10000] loss=27.1625  Lc=8.6027  Ls=1.9914\n",
      "[  1800/10000] loss=29.6747  Lc=9.2208  Ls=2.2466\n",
      "[  2000/10000] loss=30.6400  Lc=10.0448  Ls=2.1101\n",
      "[  2200/10000] loss=26.1481  Lc=8.3674  Ls=1.8827\n",
      "[  2400/10000] loss=16.4818  Lc=4.8779  Ls=1.3452\n",
      "[  2600/10000] loss=17.4041  Lc=5.9906  Ls=1.0846\n",
      "[  2800/10000] loss=18.4866  Lc=6.1824  Ls=1.2244\n",
      "[  3000/10000] loss=20.2491  Lc=5.4735  Ls=1.8604\n",
      "[  3200/10000] loss=19.6255  Lc=6.3679  Ls=1.3780\n",
      "[  3400/10000] loss=24.4739  Lc=7.5654  Ls=1.8686\n",
      "[  3600/10000] loss=21.9627  Lc=6.8120  Ls=1.6678\n",
      "[  3800/10000] loss=15.4513  Lc=5.1262  Ls=1.0398\n",
      "[  4000/10000] loss=21.1858  Lc=6.9780  Ls=1.4460\n",
      "[  4200/10000] loss=24.5297  Lc=7.9976  Ls=1.7069\n",
      "[  4400/10000] loss=15.7533  Lc=4.9947  Ls=1.1528\n",
      "[  4600/10000] loss=32.6363  Lc=9.9331  Ls=2.5540\n",
      "[  4800/10000] loss=19.8248  Lc=6.1070  Ls=1.5222\n",
      "[  5000/10000] loss=29.7575  Lc=9.4943  Ls=2.1538\n",
      "[  5200/10000] loss=18.8726  Lc=6.2418  Ls=1.2778\n",
      "[  5400/10000] loss=12.5027  Lc=4.2350  Ls=0.8065\n",
      "[  5600/10000] loss=28.0313  Lc=8.7232  Ls=2.1170\n",
      "[  5800/10000] loss=19.8380  Lc=6.5034  Ls=1.3662\n",
      "[  6000/10000] loss=19.5660  Lc=6.4970  Ls=1.3144\n",
      "[  6200/10000] loss=20.1553  Lc=6.6932  Ls=1.3538\n",
      "[  6400/10000] loss=18.1535  Lc=6.0128  Ls=1.2256\n",
      "[  6600/10000] loss=23.2048  Lc=7.1959  Ls=1.7626\n",
      "[  6800/10000] loss=29.9268  Lc=8.9384  Ls=2.4100\n",
      "[  7000/10000] loss=18.8553  Lc=5.8687  Ls=1.4236\n",
      "[  7200/10000] loss=16.8961  Lc=5.6470  Ls=1.1204\n",
      "[  7400/10000] loss=23.6976  Lc=6.9975  Ls=1.9405\n",
      "[  7600/10000] loss=23.2072  Lc=6.7820  Ls=1.9286\n",
      "[  7800/10000] loss=24.8292  Lc=7.5811  Ls=1.9334\n",
      "[  8000/10000] loss=24.7005  Lc=8.0874  Ls=1.7051\n",
      "[  8200/10000] loss=18.1151  Lc=5.8605  Ls=1.2788\n",
      "[  8400/10000] loss=20.4042  Lc=6.1405  Ls=1.6246\n",
      "[  8600/10000] loss=14.2175  Lc=4.7981  Ls=0.9243\n",
      "[  8800/10000] loss=17.8750  Lc=5.9971  Ls=1.1762\n",
      "[  9000/10000] loss=15.1840  Lc=5.0447  Ls=1.0189\n",
      "[  9200/10000] loss=18.7095  Lc=6.0938  Ls=1.3044\n",
      "[  9400/10000] loss=15.1680  Lc=4.9952  Ls=1.0355\n",
      "[  9600/10000] loss=14.4650  Lc=5.1673  Ls=0.8261\n",
      "[  9800/10000] loss=15.8184  Lc=5.1721  Ls=1.0948\n",
      "[ 10000/10000] loss=15.6505  Lc=5.3413  Ls=0.9936\n",
      "[final] saved: ./Folder/adain_runs3/c2_s5_a1_it10000/decoder_final3.pth\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Neural Style Transfer (AdaIN, Huang & Belongie 2017)\n",
    "# - Hyperparameter sweep over lambda_content and lambda_style\n",
    "# - Optional alpha blending for AdaIN targets\n",
    "# - Saves sample grids & checkpoints every 200 iterations\n",
    "# - FIXED: config copying works even if Cfg uses class attributes\n",
    "# ============================================================\n",
    "\n",
    "import os, random, time, json\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models, utils\n",
    "\n",
    "# -----------------------------\n",
    "# Device & Reproducibility\n",
    "# -----------------------------\n",
    "torch.backends.cudnn.benchmark = True\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "class Cfg:\n",
    "    # Paths (adjust if needed)\n",
    "    data_root = str((Path.cwd() / \"\").resolve())\n",
    "    content_dir = os.path.join(data_root, \"content\")\n",
    "    style_dir   = os.path.join(data_root, \"style\")\n",
    "    out_dir     = \"./Folder/adain_runs3\"\n",
    "\n",
    "    # Training\n",
    "    image_size_crop   = 256\n",
    "    resize_shorter_to = 512\n",
    "    batch_size = 8\n",
    "    num_workers = 2\n",
    "    lr = 1e-4\n",
    "    max_iterations = 80_000\n",
    "\n",
    "    # Logging & saving\n",
    "    save_every = 5000            # <-- save grid + checkpoint every 200 steps\n",
    "    log_every  = 200\n",
    "\n",
    "    # Loss weights (total = λc * Lc + λs * Ls)\n",
    "    lambda_content = 0.5\n",
    "    lambda_style   = 10.0\n",
    "\n",
    "    # AdaIN blend strength for target feature (1.0 = pure style stats)\n",
    "    alpha = 1.0\n",
    "\n",
    "    # Resume (leave None for fresh runs)\n",
    "    resume = None\n",
    "\n",
    "cfg = Cfg()\n",
    "os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "# Helper: turn a Cfg instance (class-level attrs) into a dict\n",
    "def cfg_to_dict(obj):\n",
    "    out = {}\n",
    "    for k in dir(obj):\n",
    "        if k.startswith(\"_\"):\n",
    "            continue\n",
    "        v = getattr(obj, k)\n",
    "        if callable(v):\n",
    "            continue\n",
    "        out[k] = v\n",
    "    return out\n",
    "\n",
    "print(\"CFG:\", cfg_to_dict(cfg))\n",
    "\n",
    "# -----------------------------\n",
    "# Basic image helpers\n",
    "# -----------------------------\n",
    "IMG_EXTS = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n",
    "\n",
    "def count_imgs(p):\n",
    "    p = Path(p)\n",
    "    return sum(1 for f in p.rglob(\"*\") if f.suffix.lower() in IMG_EXTS)\n",
    "\n",
    "def first_img(p):\n",
    "    p = Path(p)\n",
    "    for f in p.rglob(\"*\"):\n",
    "        if f.suffix.lower() in IMG_EXTS:\n",
    "            return str(f)\n",
    "    return None\n",
    "\n",
    "print(\"content_dir exists:\", os.path.isdir(cfg.content_dir), \"n_images:\", count_imgs(cfg.content_dir) if os.path.isdir(cfg.content_dir) else 0)\n",
    "print(\"style_dir   exists:\", os.path.isdir(cfg.style_dir),   \"n_images:\", count_imgs(cfg.style_dir)   if os.path.isdir(cfg.style_dir)   else 0)\n",
    "print(\"example content:\", first_img(cfg.content_dir))\n",
    "print(\"example style  :\", first_img(cfg.style_dir))\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class ImageFolderFlat(Dataset):\n",
    "    def __init__(self, root, resize_shorter_to=512, crop_size=256):\n",
    "        self.paths = []\n",
    "        for p in sorted(Path(root).rglob(\"*\")):\n",
    "            if p.suffix.lower() in IMG_EXTS:\n",
    "                self.paths.append(str(p))\n",
    "        if not self.paths:\n",
    "            raise RuntimeError(f\"No images found under {root}\")\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Lambda(lambda im: im.convert(\"RGB\")),\n",
    "            T.Resize(resize_shorter_to, interpolation=Image.BICUBIC),\n",
    "            T.RandomCrop(crop_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx % len(self.paths)]\n",
    "        img = Image.open(p)\n",
    "        return self.transform(img)\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Iterates over content images; for each content item, pick a random style item.\n",
    "    \"\"\"\n",
    "    def __init__(self, content_root, style_root, resize_shorter_to=512, crop_size=256):\n",
    "        self.content_ds = ImageFolderFlat(content_root, resize_shorter_to, crop_size)\n",
    "        self.style_ds   = ImageFolderFlat(style_root,   resize_shorter_to, crop_size)\n",
    "        self.style_len  = len(self.style_ds)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.content_ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        content_img = self.content_ds[idx]\n",
    "        style_img   = self.style_ds[random.randrange(self.style_len)]\n",
    "        return content_img, style_img\n",
    "\n",
    "# Build dataloader once; reused across sweeps\n",
    "train_ds = PairDataset(cfg.content_dir, cfg.style_dir, cfg.resize_shorter_to, cfg.image_size_crop)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=cfg.num_workers,\n",
    "    pin_memory=(device.type == 'cuda'),\n",
    "    drop_last=True\n",
    ")\n",
    "print(\"Dataset size:\", len(train_ds), \"Batches/epoch (approx):\", len(train_loader))\n",
    "\n",
    "# -----------------------------\n",
    "# VGG Encoder & AdaIN\n",
    "# -----------------------------\n",
    "# Map torchvision VGG19 feature indices to friendly names\n",
    "LAYER_NAME_MAP = {\n",
    "    1 : 'relu1_1',\n",
    "    6 : 'relu2_1',\n",
    "    11: 'relu3_1',\n",
    "    20: 'relu4_1',\n",
    "}\n",
    "\n",
    "STYLE_LAYERS = ['relu1_1','relu2_1','relu3_1','relu4_1']\n",
    "CONTENT_LAYER = 'relu4_1'\n",
    "\n",
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    # feat: (B, C, H, W)\n",
    "    B, C = feat.size()[:2]\n",
    "    feat_var = feat.view(B, C, -1).var(dim=2, unbiased=False) + eps\n",
    "    feat_std = feat_var.sqrt().view(B, C, 1, 1)\n",
    "    feat_mean = feat.view(B, C, -1).mean(dim=2).view(B, C, 1, 1)\n",
    "    return feat_mean, feat_std\n",
    "\n",
    "def adain(content_feat, style_feat, eps=1e-5):\n",
    "    # Channel-wise align mean & std of content to style\n",
    "    c_mean, c_std = calc_mean_std(content_feat, eps)\n",
    "    s_mean, s_std = calc_mean_std(style_feat, eps)\n",
    "    normalized = (content_feat - c_mean) / c_std\n",
    "    return normalized * s_std + s_mean\n",
    "\n",
    "class VGGEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    VGG-19 (imagenet) up to relu4_1. Returns dict of selected layer activations.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            self.vgg = models.vgg19(weights=models.VGG19_Weights.DEFAULT).features\n",
    "        except Exception:\n",
    "            self.vgg = models.vgg19(pretrained=True).features\n",
    "        for p in self.vgg.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def forward(self, x, out_keys=('relu1_1','relu2_1','relu3_1','relu4_1')):\n",
    "        feats = {}\n",
    "        h = x\n",
    "        for i, layer in enumerate(self.vgg):\n",
    "            h = layer(h)\n",
    "            name = LAYER_NAME_MAP.get(i, None)\n",
    "            if name in out_keys:\n",
    "                feats[name] = h\n",
    "            if i >= 20:  # after relu4_1\n",
    "                pass\n",
    "        return feats\n",
    "\n",
    "# -----------------------------\n",
    "# Decoder (mirror-ish of VGG)\n",
    "# -----------------------------\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            # relu4_1 -> block3\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(512, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 128, 3), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(128, 128, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(128, 64, 3), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(64, 64, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(64, 3, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.body(x)\n",
    "\n",
    "# -----------------------------\n",
    "# Loss wrapper & style loss\n",
    "# -----------------------------\n",
    "class LossNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = VGGEncoder()\n",
    "        self.encoder.eval()\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def encode(self, x, keys=None):\n",
    "        return self.encoder(x, out_keys=tuple(keys) if keys else tuple(STYLE_LAYERS))\n",
    "\n",
    "def mean_std_loss(x_feats, y_feats):\n",
    "    \"\"\"\n",
    "    IN-statistics style loss: sum over layers of (mean MSE + std MSE)\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    for k in STYLE_LAYERS:\n",
    "        xm, xs = calc_mean_std(x_feats[k])\n",
    "        ym, ys = calc_mean_std(y_feats[k])\n",
    "        loss = loss + F.mse_loss(xm, ym) + F.mse_loss(xs, ys)\n",
    "    return loss\n",
    "\n",
    "# -----------------------------\n",
    "# Utility: (de)normalization & saving\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def denorm_for_save(x):\n",
    "    # x is normalized (ImageNet), bring it back to [0,1] for saving\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=x.device).view(1,3,1,1)\n",
    "    std  = torch.tensor([0.229, 0.224, 0.225], device=x.device).view(1,3,1,1)\n",
    "    y = x * std + mean\n",
    "    return torch.clamp(y, 0, 1)\n",
    "\n",
    "# -----------------------------\n",
    "# Training: one run with overrides  (FIXED cfg copy)\n",
    "# -----------------------------\n",
    "def train_once(cfg_base, overrides):\n",
    "    # Build a dict from cfg_base (even if class-level attrs), then apply overrides\n",
    "    base_dict = cfg_to_dict(cfg_base)\n",
    "    base_dict.update(overrides)\n",
    "    run_cfg = SimpleNamespace(**base_dict)\n",
    "\n",
    "    # Unique run folder\n",
    "    tag = f\"c{run_cfg.lambda_content:g}_s{run_cfg.lambda_style:g}_a{run_cfg.alpha:g}_it{run_cfg.max_iterations}\"\n",
    "    run_out = os.path.join(run_cfg.out_dir, tag)\n",
    "    os.makedirs(run_out, exist_ok=True)\n",
    "\n",
    "    # Fresh model & optimizer\n",
    "    decoder = Decoder().to(device)\n",
    "    lossnet = LossNet().to(device).eval()\n",
    "    optimizer = torch.optim.Adam(decoder.parameters(), lr=run_cfg.lr)\n",
    "\n",
    "    # Resume (decoder-only resume supported; optional)\n",
    "    start_iter = 0\n",
    "    if run_cfg.resume:\n",
    "        data = torch.load(run_cfg.resume, map_location=device)\n",
    "        decoder.load_state_dict(data['decoder'], strict=True)\n",
    "        if 'optimizer' in data:\n",
    "            optimizer.load_state_dict(data['optimizer'])\n",
    "        start_iter = data.get('iteration', 0)\n",
    "        print(f\"[resume] loaded {run_cfg.resume} @ iter {start_iter}\")\n",
    "\n",
    "    global_iter = start_iter\n",
    "    data_iter = iter(train_loader)\n",
    "    decoder.train()\n",
    "\n",
    "    print(f\"\\n=== RUN {tag} ===\")\n",
    "    print({k: getattr(run_cfg, k) for k in ['lambda_content','lambda_style','alpha','max_iterations','save_every','log_every']})\n",
    "\n",
    "    while global_iter < run_cfg.max_iterations:\n",
    "        try:\n",
    "            content, style = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(train_loader)\n",
    "            content, style = next(data_iter)\n",
    "\n",
    "        content = content.to(device, non_blocking=True)\n",
    "        style   = style.to(device, non_blocking=True)\n",
    "\n",
    "        # --- Targets ---\n",
    "        with torch.no_grad():\n",
    "            c4 = lossnet.encoder(content, out_keys=['relu4_1'])['relu4_1']\n",
    "            s4 = lossnet.encoder(style,   out_keys=['relu4_1'])['relu4_1']\n",
    "        t_adain = adain(c4, s4)\n",
    "        t_feat  = run_cfg.alpha * t_adain + (1.0 - run_cfg.alpha) * c4  # blend with content features\n",
    "\n",
    "        # --- Decode ---\n",
    "        g_img = decoder(t_feat)\n",
    "        g_img_clamped = torch.clamp(g_img, -3.0, 3.0)\n",
    "\n",
    "        # --- Re-encode generated (with grad) ---\n",
    "        g_feats_all = lossnet.encoder(g_img_clamped, out_keys=STYLE_LAYERS)\n",
    "\n",
    "        # --- Style targets (no grad) ---\n",
    "        with torch.no_grad():\n",
    "            s_feats_all = lossnet.encoder(style, out_keys=STYLE_LAYERS)\n",
    "\n",
    "        # --- Losses ---\n",
    "        loss_c = F.mse_loss(g_feats_all[CONTENT_LAYER], t_feat)\n",
    "        loss_s = mean_std_loss(g_feats_all, s_feats_all)\n",
    "        loss   = run_cfg.lambda_content * loss_c + run_cfg.lambda_style * loss_s\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        global_iter += 1\n",
    "\n",
    "        if global_iter % run_cfg.log_every == 0:\n",
    "            print(f\"[{global_iter:>6d}/{run_cfg.max_iterations}] \"\n",
    "                  f\"loss={loss.item():.4f}  Lc={loss_c.item():.4f}  Ls={loss_s.item():.4f}\")\n",
    "\n",
    "        if global_iter % run_cfg.save_every == 0:\n",
    "            with torch.no_grad():\n",
    "                c_show = denorm_for_save(content[:2])\n",
    "                s_show = denorm_for_save(style[:2])\n",
    "                g_show = denorm_for_save(g_img_clamped[:2])\n",
    "                samples = torch.cat([c_show, s_show, g_show], dim=0)\n",
    "            grid = utils.make_grid(samples, nrow=2)\n",
    "            grid_path = os.path.join(run_out, f\"samples_iter_{global_iter}.png\")\n",
    "            utils.save_image(grid, grid_path)\n",
    "\n",
    "            ckpt = {\n",
    "                'iteration': global_iter,\n",
    "                'decoder': decoder.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'cfg': vars(run_cfg),\n",
    "                'time': time.time(),\n",
    "            }\n",
    "            ckpt_path = os.path.join(run_out, f\"decoder_iter3_{global_iter}.pth\")\n",
    "            torch.save(ckpt, ckpt_path)\n",
    "            try:\n",
    "                os.sync()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Final save\n",
    "    final_path = os.path.join(run_out, \"decoder_final3.pth\")\n",
    "    torch.save({'iteration': global_iter, 'decoder': decoder.state_dict(), 'cfg': vars(run_cfg)}, final_path)\n",
    "    print(f\"[final] saved: {final_path}\")\n",
    "\n",
    "    return {\n",
    "        \"tag\": tag,\n",
    "        \"final_iteration\": global_iter,\n",
    "        \"out_dir\": run_out,\n",
    "        \"lambda_content\": run_cfg.lambda_content,\n",
    "        \"lambda_style\": run_cfg.lambda_style,\n",
    "        \"alpha\": run_cfg.alpha\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation: stylize fixed pairs with alpha sweep (after training)\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def stylize_pairs(ckpt_path, pairs, alpha_vals=(1.0,), save_path=\"eval_grid.png\"):\n",
    "    # Load trained decoder\n",
    "    decoder = Decoder().to(device).eval()\n",
    "    data = torch.load(ckpt_path, map_location=device)\n",
    "    decoder.load_state_dict(data['decoder'], strict=True)\n",
    "\n",
    "    enc = VGGEncoder().to(device).eval()\n",
    "\n",
    "    to_norm = T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    to_tensor = T.Compose([\n",
    "        T.Lambda(lambda im: im.convert(\"RGB\")),\n",
    "        T.Resize(512, interpolation=Image.BICUBIC),\n",
    "        T.CenterCrop(256),\n",
    "        T.ToTensor(),\n",
    "        to_norm\n",
    "    ])\n",
    "\n",
    "    rows = []\n",
    "    for c_path, s_path in pairs:\n",
    "        c = to_tensor(Image.open(c_path)).unsqueeze(0).to(device)\n",
    "        s = to_tensor(Image.open(s_path)).unsqueeze(0).to(device)\n",
    "        c4 = enc(c, out_keys=['relu4_1'])['relu4_1']\n",
    "        s4 = enc(s, out_keys=['relu4_1'])['relu4_1']\n",
    "        t  = adain(c4, s4)\n",
    "        row_imgs = [denorm_for_save(c), denorm_for_save(s)]\n",
    "        for a in alpha_vals:\n",
    "            t_blend = a * t + (1.0 - a) * c4\n",
    "            y = decoder(t_blend).clamp(-3,3)\n",
    "            row_imgs.append(denorm_for_save(y))\n",
    "        rows.append(torch.cat(row_imgs, dim=0))\n",
    "\n",
    "    grid = utils.make_grid(torch.cat(rows, dim=0), nrow=2 + len(alpha_vals))\n",
    "    utils.save_image(grid, save_path)\n",
    "    print(\"Saved eval grid:\", save_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Sweep definition & execution\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Define a first-pass sweep over style weights; keep λc = 1, α = 1\n",
    "    sweep = []\n",
    "    for lam_s in [0.5, 1.0, 2.0, 5.0, 10.0, 20.0]:\n",
    "        sweep.append({\"lambda_content\": 1.0, \"lambda_style\": lam_s, \"alpha\": 1.0, \"max_iterations\": 10_000})\n",
    "\n",
    "    # Optional: vary content weight a bit (still α = 1)\n",
    "    for lam_c in [0.5, 1.0, 2.0]:\n",
    "        sweep.append({\"lambda_content\": lam_c, \"lambda_style\": 5.0, \"alpha\": 1.0, \"max_iterations\": 10_000})\n",
    "\n",
    "    results = []\n",
    "    for overrides in sweep:\n",
    "        results.append(train_once(cfg, overrides))\n",
    "\n",
    "    # Save a summary JSON\n",
    "    with open(os.path.join(cfg.out_dir, \"sweep_results.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    # Example: quick evaluation grid for one trained checkpoint (edit paths if needed)\n",
    "    try:\n",
    "        ex_content = first_img(cfg.content_dir)\n",
    "        ex_style   = first_img(cfg.style_dir)\n",
    "        if ex_content and ex_style:\n",
    "            ckpt_example = Path(cfg.out_dir) / \"c1_s5_a1_it10000\" / \"decoder_final.pth\"\n",
    "            if ckpt_example.exists():\n",
    "                stylize_pairs(\n",
    "                    str(ckpt_example),\n",
    "                    pairs=[(ex_content, ex_style)],           # add more pairs here\n",
    "                    alpha_vals=(0.3, 0.6, 1.0),\n",
    "                    save_path=str(Path(cfg.out_dir) / \"eval_s5.png\")\n",
    "                )\n",
    "    except Exception as e:\n",
    "        print(\"Eval example skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f79db15f-9ed6-404a-8654-884eaf827bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "CFG: {'alpha': 1.0, 'batch_size': 8, 'content_dir': '/workspace/content', 'data_root': '/workspace', 'image_size_crop': 256, 'lambda_content': 0.8, 'lambda_style': 58.0, 'log_every': 200, 'lr': 0.0001, 'max_iterations': 80000, 'num_workers': 2, 'out_dir': './Folder/adain_runs4', 'resize_shorter_to': 512, 'resume': None, 'save_every': 5000, 'style_dir': '/workspace/style'}\n",
      "content_dir exists: True n_images: 49981\n",
      "style_dir   exists: True n_images: 49981\n",
      "example content: /workspace/content/000000000045.jpg\n",
      "example style  : /workspace/style/1.jpg\n",
      "Dataset size: 49981 Batches/epoch (approx): 6247\n",
      "\n",
      "=== RUN c1_s0.5_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 0.5, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=10.6290  Lc=8.4794  Ls=4.2993\n",
      "[   400/10000] loss=7.4365  Lc=5.9102  Ls=3.0526\n",
      "[   600/10000] loss=9.6552  Lc=7.7455  Ls=3.8193\n",
      "[   800/10000] loss=9.7455  Lc=7.9632  Ls=3.5646\n",
      "[  1000/10000] loss=9.5849  Lc=7.8290  Ls=3.5119\n",
      "[  1200/10000] loss=9.2152  Lc=7.5149  Ls=3.4005\n",
      "[  1400/10000] loss=6.3474  Lc=5.2160  Ls=2.2628\n",
      "[  1600/10000] loss=5.8869  Lc=4.9421  Ls=1.8896\n",
      "[  1800/10000] loss=8.5288  Lc=6.9899  Ls=3.0778\n",
      "[  2000/10000] loss=10.3708  Lc=8.2967  Ls=4.1480\n",
      "[  2200/10000] loss=6.0084  Lc=4.9875  Ls=2.0419\n",
      "[  2400/10000] loss=5.5248  Lc=4.5710  Ls=1.9076\n",
      "[  2600/10000] loss=6.4280  Lc=5.1715  Ls=2.5130\n",
      "[  2800/10000] loss=7.1040  Lc=5.7986  Ls=2.6107\n",
      "[  3000/10000] loss=5.7896  Lc=4.5906  Ls=2.3979\n",
      "[  3200/10000] loss=7.1339  Lc=6.0436  Ls=2.1805\n",
      "[  3400/10000] loss=7.9566  Lc=6.4798  Ls=2.9535\n",
      "[  3600/10000] loss=6.1128  Lc=5.1416  Ls=1.9425\n",
      "[  3800/10000] loss=4.2851  Lc=3.4587  Ls=1.6529\n",
      "[  4000/10000] loss=6.1213  Lc=5.0683  Ls=2.1061\n",
      "[  4200/10000] loss=6.3805  Lc=5.1234  Ls=2.5143\n",
      "[  4400/10000] loss=6.5313  Lc=5.4253  Ls=2.2120\n",
      "[  4600/10000] loss=5.1268  Lc=4.2238  Ls=1.8060\n",
      "[  4800/10000] loss=8.4286  Lc=6.9596  Ls=2.9380\n",
      "[  5000/10000] loss=5.8397  Lc=4.7515  Ls=2.1766\n",
      "[  5200/10000] loss=6.7879  Lc=5.5279  Ls=2.5201\n",
      "[  5400/10000] loss=6.2904  Lc=5.2571  Ls=2.0666\n",
      "[  5600/10000] loss=5.8737  Lc=4.9700  Ls=1.8072\n",
      "[  5800/10000] loss=6.3699  Lc=5.2620  Ls=2.2158\n",
      "[  6000/10000] loss=5.6578  Lc=4.5733  Ls=2.1691\n",
      "[  6200/10000] loss=6.8381  Lc=5.5688  Ls=2.5386\n",
      "[  6400/10000] loss=5.0819  Lc=4.0435  Ls=2.0769\n",
      "[  6600/10000] loss=6.5709  Lc=5.3796  Ls=2.3826\n",
      "[  6800/10000] loss=4.0858  Lc=3.3479  Ls=1.4757\n",
      "[  7000/10000] loss=5.8005  Lc=4.7954  Ls=2.0103\n",
      "[  7200/10000] loss=5.3314  Lc=4.3468  Ls=1.9693\n",
      "[  7400/10000] loss=6.9105  Lc=5.6663  Ls=2.4885\n",
      "[  7600/10000] loss=5.2895  Lc=4.3281  Ls=1.9229\n",
      "[  7800/10000] loss=4.0763  Lc=3.4327  Ls=1.2870\n",
      "[  8000/10000] loss=8.3652  Lc=6.5197  Ls=3.6909\n",
      "[  8200/10000] loss=5.1984  Lc=4.3045  Ls=1.7877\n",
      "[  8400/10000] loss=6.2790  Lc=4.9243  Ls=2.7093\n",
      "[  8600/10000] loss=5.8612  Lc=4.8770  Ls=1.9684\n",
      "[  8800/10000] loss=5.4091  Lc=4.5096  Ls=1.7990\n",
      "[  9000/10000] loss=6.5626  Lc=5.4072  Ls=2.3108\n",
      "[  9200/10000] loss=6.3591  Lc=5.1571  Ls=2.4041\n",
      "[  9400/10000] loss=6.5656  Lc=5.2450  Ls=2.6412\n",
      "[  9600/10000] loss=4.7765  Lc=3.9338  Ls=1.6853\n",
      "[  9800/10000] loss=4.6966  Lc=3.7669  Ls=1.8595\n",
      "[ 10000/10000] loss=12.9867  Lc=9.7120  Ls=6.5494\n",
      "[final] saved: ./Folder/adain_runs4/c1_s0.5_a1_it10000/decoder_final4.pth\n",
      "\n",
      "=== RUN c1_s1_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 1.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=13.5478  Lc=10.3332  Ls=3.2146\n",
      "[   400/10000] loss=10.0465  Lc=7.3564  Ls=2.6901\n",
      "[   600/10000] loss=15.2565  Lc=10.9236  Ls=4.3330\n",
      "[   800/10000] loss=8.2222  Lc=5.9133  Ls=2.3089\n",
      "[  1000/10000] loss=9.6872  Lc=7.3585  Ls=2.3287\n",
      "[  1200/10000] loss=10.0346  Lc=7.4221  Ls=2.6125\n",
      "[  1400/10000] loss=9.5454  Lc=6.8243  Ls=2.7211\n",
      "[  1600/10000] loss=7.4605  Lc=5.6500  Ls=1.8105\n",
      "[  1800/10000] loss=9.3668  Lc=6.9863  Ls=2.3806\n",
      "[  2000/10000] loss=7.1175  Lc=5.5811  Ls=1.5364\n",
      "[  2200/10000] loss=6.7197  Lc=5.1547  Ls=1.5649\n",
      "[  2400/10000] loss=7.7937  Lc=5.6267  Ls=2.1669\n",
      "[  2600/10000] loss=6.2917  Lc=4.4742  Ls=1.8175\n",
      "[  2800/10000] loss=6.2894  Lc=4.7713  Ls=1.5180\n",
      "[  3000/10000] loss=8.1673  Lc=6.4623  Ls=1.7050\n",
      "[  3200/10000] loss=8.9115  Lc=6.1337  Ls=2.7778\n",
      "[  3400/10000] loss=6.7163  Lc=5.0955  Ls=1.6208\n",
      "[  3600/10000] loss=5.6024  Lc=4.2650  Ls=1.3373\n",
      "[  3800/10000] loss=7.4938  Lc=5.6610  Ls=1.8329\n",
      "[  4000/10000] loss=5.9002  Lc=4.4369  Ls=1.4634\n",
      "[  4200/10000] loss=8.2748  Lc=5.9526  Ls=2.3222\n",
      "[  4400/10000] loss=7.4493  Lc=5.4950  Ls=1.9544\n",
      "[  4600/10000] loss=6.9087  Lc=5.2237  Ls=1.6849\n",
      "[  4800/10000] loss=5.4066  Lc=4.0190  Ls=1.3876\n",
      "[  5000/10000] loss=6.2409  Lc=4.7073  Ls=1.5336\n",
      "[  5200/10000] loss=6.0321  Lc=4.6284  Ls=1.4036\n",
      "[  5400/10000] loss=6.2558  Lc=4.4374  Ls=1.8184\n",
      "[  5600/10000] loss=8.4750  Lc=5.6008  Ls=2.8743\n",
      "[  5800/10000] loss=6.4461  Lc=4.8627  Ls=1.5833\n",
      "[  6000/10000] loss=11.2169  Lc=7.9554  Ls=3.2615\n",
      "[  6200/10000] loss=5.8421  Lc=4.3801  Ls=1.4620\n",
      "[  6400/10000] loss=6.2703  Lc=4.6010  Ls=1.6694\n",
      "[  6600/10000] loss=8.3438  Lc=6.0091  Ls=2.3347\n",
      "[  6800/10000] loss=6.2897  Lc=4.8505  Ls=1.4392\n",
      "[  7000/10000] loss=4.8668  Lc=3.7123  Ls=1.1545\n",
      "[  7200/10000] loss=6.3992  Lc=4.9788  Ls=1.4203\n",
      "[  7400/10000] loss=9.7385  Lc=7.0486  Ls=2.6899\n",
      "[  7600/10000] loss=4.9397  Lc=3.3668  Ls=1.5729\n",
      "[  7800/10000] loss=5.6111  Lc=4.2010  Ls=1.4101\n",
      "[  8000/10000] loss=7.0812  Lc=5.3303  Ls=1.7509\n",
      "[  8200/10000] loss=5.5770  Lc=3.9800  Ls=1.5971\n",
      "[  8400/10000] loss=8.8884  Lc=6.6997  Ls=2.1887\n",
      "[  8600/10000] loss=7.9587  Lc=5.7814  Ls=2.1773\n",
      "[  8800/10000] loss=5.9241  Lc=4.6089  Ls=1.3153\n",
      "[  9000/10000] loss=6.1845  Lc=4.8138  Ls=1.3707\n",
      "[  9200/10000] loss=6.2539  Lc=4.5812  Ls=1.6727\n",
      "[  9400/10000] loss=7.0503  Lc=5.0737  Ls=1.9765\n",
      "[  9600/10000] loss=7.6124  Lc=5.7814  Ls=1.8310\n",
      "[  9800/10000] loss=6.7076  Lc=5.2150  Ls=1.4926\n",
      "[ 10000/10000] loss=5.4907  Lc=4.1188  Ls=1.3719\n",
      "[final] saved: ./Folder/adain_runs4/c1_s1_a1_it10000/decoder_final4.pth\n",
      "\n",
      "=== RUN c1_s2_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 2.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=19.6472  Lc=11.5298  Ls=4.0587\n",
      "[   400/10000] loss=17.3381  Lc=11.7178  Ls=2.8102\n",
      "[   600/10000] loss=15.4648  Lc=10.5738  Ls=2.4455\n",
      "[   800/10000] loss=12.8545  Lc=8.4291  Ls=2.2127\n",
      "[  1000/10000] loss=10.0883  Lc=6.8379  Ls=1.6252\n",
      "[  1200/10000] loss=15.2291  Lc=8.7106  Ls=3.2593\n",
      "[  1400/10000] loss=13.0833  Lc=8.6888  Ls=2.1972\n",
      "[  1600/10000] loss=11.3915  Lc=7.6916  Ls=1.8499\n",
      "[  1800/10000] loss=10.7334  Lc=7.5051  Ls=1.6141\n",
      "[  2000/10000] loss=10.6213  Lc=7.2689  Ls=1.6762\n",
      "[  2200/10000] loss=7.7507  Lc=5.6137  Ls=1.0685\n",
      "[  2400/10000] loss=9.1550  Lc=6.2287  Ls=1.4631\n",
      "[  2600/10000] loss=7.6010  Lc=5.1229  Ls=1.2391\n",
      "[  2800/10000] loss=7.5969  Lc=5.2597  Ls=1.1686\n",
      "[  3000/10000] loss=10.7032  Lc=7.3619  Ls=1.6707\n",
      "[  3200/10000] loss=7.4175  Lc=5.1350  Ls=1.1413\n",
      "[  3400/10000] loss=11.6619  Lc=7.4795  Ls=2.0912\n",
      "[  3600/10000] loss=9.0642  Lc=5.6649  Ls=1.6996\n",
      "[  3800/10000] loss=7.0878  Lc=4.9574  Ls=1.0652\n",
      "[  4000/10000] loss=8.2568  Lc=5.1076  Ls=1.5746\n",
      "[  4200/10000] loss=12.7618  Lc=7.9157  Ls=2.4230\n",
      "[  4400/10000] loss=6.4550  Lc=4.6513  Ls=0.9019\n",
      "[  4600/10000] loss=9.5361  Lc=6.7129  Ls=1.4116\n",
      "[  4800/10000] loss=9.0031  Lc=6.0126  Ls=1.4953\n",
      "[  5000/10000] loss=7.0527  Lc=4.8745  Ls=1.0891\n",
      "[  5200/10000] loss=7.6234  Lc=4.8463  Ls=1.3886\n",
      "[  5400/10000] loss=8.4752  Lc=5.8564  Ls=1.3094\n",
      "[  5600/10000] loss=13.4755  Lc=8.7094  Ls=2.3830\n",
      "[  5800/10000] loss=7.6494  Lc=5.3297  Ls=1.1598\n",
      "[  6000/10000] loss=10.6790  Lc=7.1605  Ls=1.7592\n",
      "[  6200/10000] loss=9.6009  Lc=6.4518  Ls=1.5746\n",
      "[  6400/10000] loss=8.2311  Lc=5.8809  Ls=1.1751\n",
      "[  6600/10000] loss=7.9356  Lc=5.6428  Ls=1.1464\n",
      "[  6800/10000] loss=8.1872  Lc=5.2818  Ls=1.4527\n",
      "[  7000/10000] loss=11.6591  Lc=7.2176  Ls=2.2207\n",
      "[  7200/10000] loss=7.4742  Lc=5.0532  Ls=1.2105\n",
      "[  7400/10000] loss=9.8572  Lc=6.7556  Ls=1.5508\n",
      "[  7600/10000] loss=10.8018  Lc=6.1611  Ls=2.3204\n",
      "[  7800/10000] loss=9.6708  Lc=6.7239  Ls=1.4734\n",
      "[  8000/10000] loss=8.4502  Lc=6.1247  Ls=1.1628\n",
      "[  8200/10000] loss=5.3653  Lc=3.8462  Ls=0.7595\n",
      "[  8400/10000] loss=8.7841  Lc=5.8977  Ls=1.4432\n",
      "[  8600/10000] loss=15.4560  Lc=8.8156  Ls=3.3202\n",
      "[  8800/10000] loss=7.7597  Lc=4.7203  Ls=1.5197\n",
      "[  9000/10000] loss=8.1365  Lc=5.6587  Ls=1.2389\n",
      "[  9200/10000] loss=9.4117  Lc=6.1752  Ls=1.6183\n",
      "[  9400/10000] loss=6.9796  Lc=4.6180  Ls=1.1808\n",
      "[  9600/10000] loss=9.5359  Lc=6.4802  Ls=1.5278\n",
      "[  9800/10000] loss=9.7533  Lc=6.7970  Ls=1.4782\n",
      "[ 10000/10000] loss=6.7435  Lc=4.4838  Ls=1.1298\n",
      "[final] saved: ./Folder/adain_runs4/c1_s2_a1_it10000/decoder_final4.pth\n",
      "\n",
      "=== RUN c1_s5_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 5.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=28.5285  Lc=12.8209  Ls=3.1415\n",
      "[   400/10000] loss=21.6934  Lc=10.3745  Ls=2.2638\n",
      "[   600/10000] loss=21.2066  Lc=10.4098  Ls=2.1593\n",
      "[   800/10000] loss=21.9041  Lc=11.5851  Ls=2.0638\n",
      "[  1000/10000] loss=28.1282  Lc=12.6900  Ls=3.0876\n",
      "[  1200/10000] loss=23.6295  Lc=11.1707  Ls=2.4918\n",
      "[  1400/10000] loss=21.0535  Lc=10.8886  Ls=2.0330\n",
      "[  1600/10000] loss=19.6630  Lc=9.7851  Ls=1.9756\n",
      "[  1800/10000] loss=16.3130  Lc=9.4615  Ls=1.3703\n",
      "[  2000/10000] loss=15.9479  Lc=8.5230  Ls=1.4850\n",
      "[  2200/10000] loss=21.1750  Lc=12.2634  Ls=1.7823\n",
      "[  2400/10000] loss=12.8436  Lc=7.1633  Ls=1.1361\n",
      "[  2600/10000] loss=22.1268  Lc=11.4322  Ls=2.1389\n",
      "[  2800/10000] loss=16.4136  Lc=8.8564  Ls=1.5114\n",
      "[  3000/10000] loss=16.5217  Lc=8.6808  Ls=1.5682\n",
      "[  3200/10000] loss=19.9988  Lc=11.8798  Ls=1.6238\n",
      "[  3400/10000] loss=21.1287  Lc=10.0223  Ls=2.2213\n",
      "[  3600/10000] loss=14.2048  Lc=7.9505  Ls=1.2509\n",
      "[  3800/10000] loss=20.0192  Lc=10.3077  Ls=1.9423\n",
      "[  4000/10000] loss=14.2603  Lc=7.2511  Ls=1.4018\n",
      "[  4200/10000] loss=12.1830  Lc=6.8204  Ls=1.0725\n",
      "[  4400/10000] loss=13.9222  Lc=7.9171  Ls=1.2010\n",
      "[  4600/10000] loss=14.6117  Lc=8.1572  Ls=1.2909\n",
      "[  4800/10000] loss=16.8002  Lc=8.5709  Ls=1.6458\n",
      "[  5000/10000] loss=18.6642  Lc=10.5427  Ls=1.6243\n",
      "[  5200/10000] loss=8.0812  Lc=4.7125  Ls=0.6737\n",
      "[  5400/10000] loss=11.2965  Lc=6.0539  Ls=1.0485\n",
      "[  5600/10000] loss=18.9116  Lc=9.8907  Ls=1.8042\n",
      "[  5800/10000] loss=9.9873  Lc=5.6584  Ls=0.8658\n",
      "[  6000/10000] loss=12.3952  Lc=7.2234  Ls=1.0344\n",
      "[  6200/10000] loss=15.7472  Lc=7.5834  Ls=1.6327\n",
      "[  6400/10000] loss=13.5160  Lc=7.7639  Ls=1.1504\n",
      "[  6600/10000] loss=13.8538  Lc=6.8335  Ls=1.4041\n",
      "[  6800/10000] loss=16.0994  Lc=8.4745  Ls=1.5250\n",
      "[  7000/10000] loss=18.8908  Lc=10.8701  Ls=1.6041\n",
      "[  7200/10000] loss=11.4659  Lc=6.9441  Ls=0.9044\n",
      "[  7400/10000] loss=19.8083  Lc=10.5634  Ls=1.8490\n",
      "[  7600/10000] loss=10.9645  Lc=5.7211  Ls=1.0487\n",
      "[  7800/10000] loss=12.7554  Lc=7.5269  Ls=1.0457\n",
      "[  8000/10000] loss=16.0256  Lc=9.4224  Ls=1.3206\n",
      "[  8200/10000] loss=14.6254  Lc=7.5584  Ls=1.4134\n",
      "[  8400/10000] loss=10.0511  Lc=5.6709  Ls=0.8760\n",
      "[  8600/10000] loss=15.0258  Lc=8.0031  Ls=1.4045\n",
      "[  8800/10000] loss=12.3528  Lc=6.9938  Ls=1.0718\n",
      "[  9000/10000] loss=10.9687  Lc=6.4116  Ls=0.9114\n",
      "[  9200/10000] loss=21.4318  Lc=10.2544  Ls=2.2355\n",
      "[  9400/10000] loss=11.8076  Lc=6.9699  Ls=0.9675\n",
      "[  9600/10000] loss=17.1663  Lc=9.2113  Ls=1.5910\n",
      "[  9800/10000] loss=9.1490  Lc=5.3874  Ls=0.7523\n",
      "[ 10000/10000] loss=11.1308  Lc=6.5308  Ls=0.9200\n",
      "[final] saved: ./Folder/adain_runs4/c1_s5_a1_it10000/decoder_final4.pth\n",
      "\n",
      "=== RUN c1_s10_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 10.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=42.3131  Lc=12.7288  Ls=2.9584\n",
      "[   400/10000] loss=51.5139  Lc=13.3375  Ls=3.8176\n",
      "[   600/10000] loss=32.9396  Lc=11.3829  Ls=2.1557\n",
      "[   800/10000] loss=30.3297  Lc=10.8326  Ls=1.9497\n",
      "[  1000/10000] loss=23.3408  Lc=9.6304  Ls=1.3710\n",
      "[  1200/10000] loss=45.5811  Lc=15.1638  Ls=3.0417\n",
      "[  1400/10000] loss=33.6246  Lc=13.3788  Ls=2.0246\n",
      "[  1600/10000] loss=18.6682  Lc=7.6440  Ls=1.1024\n",
      "[  1800/10000] loss=33.0674  Lc=12.0457  Ls=2.1022\n",
      "[  2000/10000] loss=38.9244  Lc=12.1681  Ls=2.6756\n",
      "[  2200/10000] loss=32.5563  Lc=12.2421  Ls=2.0314\n",
      "[  2400/10000] loss=19.5079  Lc=8.2780  Ls=1.1230\n",
      "[  2600/10000] loss=17.4186  Lc=7.7298  Ls=0.9689\n",
      "[  2800/10000] loss=39.9661  Lc=13.5126  Ls=2.6453\n",
      "[  3000/10000] loss=21.6460  Lc=9.6514  Ls=1.1995\n",
      "[  3200/10000] loss=23.9926  Lc=8.3744  Ls=1.5618\n",
      "[  3400/10000] loss=24.0823  Lc=11.0058  Ls=1.3077\n",
      "[  3600/10000] loss=18.9067  Lc=8.5997  Ls=1.0307\n",
      "[  3800/10000] loss=19.4051  Lc=8.2398  Ls=1.1165\n",
      "[  4000/10000] loss=26.9241  Lc=12.5280  Ls=1.4396\n",
      "[  4200/10000] loss=22.5500  Lc=9.0443  Ls=1.3506\n",
      "[  4400/10000] loss=22.2239  Lc=10.6705  Ls=1.1553\n",
      "[  4600/10000] loss=49.6488  Lc=17.4196  Ls=3.2229\n",
      "[  4800/10000] loss=22.3443  Lc=10.4805  Ls=1.1864\n",
      "[  5000/10000] loss=29.2054  Lc=11.9892  Ls=1.7216\n",
      "[  5200/10000] loss=31.1237  Lc=9.7557  Ls=2.1368\n",
      "[  5400/10000] loss=18.6453  Lc=8.7859  Ls=0.9859\n",
      "[  5600/10000] loss=22.9352  Lc=7.6695  Ls=1.5266\n",
      "[  5800/10000] loss=27.8363  Lc=12.9954  Ls=1.4841\n",
      "[  6000/10000] loss=19.3708  Lc=7.6221  Ls=1.1749\n",
      "[  6200/10000] loss=15.9284  Lc=6.9436  Ls=0.8985\n",
      "[  6400/10000] loss=23.9217  Lc=11.2956  Ls=1.2626\n",
      "[  6600/10000] loss=28.8259  Lc=11.9685  Ls=1.6857\n",
      "[  6800/10000] loss=26.2662  Lc=11.6588  Ls=1.4607\n",
      "[  7000/10000] loss=19.4908  Lc=9.5721  Ls=0.9919\n",
      "[  7200/10000] loss=24.2528  Lc=11.4480  Ls=1.2805\n",
      "[  7400/10000] loss=26.8302  Lc=11.8305  Ls=1.5000\n",
      "[  7600/10000] loss=20.6811  Lc=8.4875  Ls=1.2194\n",
      "[  7800/10000] loss=16.3483  Lc=8.2112  Ls=0.8137\n",
      "[  8000/10000] loss=26.1079  Lc=11.9402  Ls=1.4168\n",
      "[  8200/10000] loss=17.9654  Lc=9.1503  Ls=0.8815\n",
      "[  8400/10000] loss=17.8673  Lc=7.8965  Ls=0.9971\n",
      "[  8600/10000] loss=28.1251  Lc=13.5927  Ls=1.4532\n",
      "[  8800/10000] loss=18.6363  Lc=8.1903  Ls=1.0446\n",
      "[  9000/10000] loss=18.0612  Lc=8.2202  Ls=0.9841\n",
      "[  9200/10000] loss=20.2314  Lc=8.9052  Ls=1.1326\n",
      "[  9400/10000] loss=16.4758  Lc=7.1377  Ls=0.9338\n",
      "[  9600/10000] loss=16.8107  Lc=7.4757  Ls=0.9335\n",
      "[  9800/10000] loss=18.4177  Lc=9.3961  Ls=0.9022\n",
      "[ 10000/10000] loss=18.4642  Lc=9.1226  Ls=0.9342\n",
      "[final] saved: ./Folder/adain_runs4/c1_s10_a1_it10000/decoder_final4.pth\n",
      "\n",
      "=== RUN c1_s20_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 20.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=88.2489  Lc=17.6842  Ls=3.5282\n",
      "[   400/10000] loss=59.3748  Lc=14.3089  Ls=2.2533\n",
      "[   600/10000] loss=61.5764  Lc=12.4580  Ls=2.4559\n",
      "[   800/10000] loss=98.9635  Lc=16.8900  Ls=4.1037\n",
      "[  1000/10000] loss=66.8245  Lc=15.3515  Ls=2.5736\n",
      "[  1200/10000] loss=41.4975  Lc=10.1925  Ls=1.5653\n",
      "[  1400/10000] loss=31.4718  Lc=10.2005  Ls=1.0636\n",
      "[  1600/10000] loss=80.9396  Lc=19.2614  Ls=3.0839\n",
      "[  1800/10000] loss=49.8798  Lc=13.3724  Ls=1.8254\n",
      "[  2000/10000] loss=36.1089  Lc=11.7879  Ls=1.2161\n",
      "[  2200/10000] loss=45.0844  Lc=13.4779  Ls=1.5803\n",
      "[  2400/10000] loss=40.9423  Lc=11.2146  Ls=1.4864\n",
      "[  2600/10000] loss=45.7028  Lc=13.7717  Ls=1.5966\n",
      "[  2800/10000] loss=41.9352  Lc=14.1243  Ls=1.3905\n",
      "[  3000/10000] loss=56.6137  Lc=13.0678  Ls=2.1773\n",
      "[  3200/10000] loss=63.9248  Lc=14.5786  Ls=2.4673\n",
      "[  3400/10000] loss=41.9426  Lc=13.0680  Ls=1.4437\n",
      "[  3600/10000] loss=35.4011  Lc=10.9568  Ls=1.2222\n",
      "[  3800/10000] loss=32.9173  Lc=11.4455  Ls=1.0736\n",
      "[  4000/10000] loss=32.9331  Lc=10.4483  Ls=1.1242\n",
      "[  4200/10000] loss=46.2501  Lc=14.1066  Ls=1.6072\n",
      "[  4400/10000] loss=40.9215  Lc=14.5589  Ls=1.3181\n",
      "[  4600/10000] loss=27.8733  Lc=7.8367  Ls=1.0018\n",
      "[  4800/10000] loss=45.0753  Lc=14.8223  Ls=1.5126\n",
      "[  5000/10000] loss=49.2012  Lc=13.0421  Ls=1.8080\n",
      "[  5200/10000] loss=33.5330  Lc=8.3591  Ls=1.2587\n",
      "[  5400/10000] loss=48.7564  Lc=12.7137  Ls=1.8021\n",
      "[  5600/10000] loss=53.1642  Lc=16.2458  Ls=1.8459\n",
      "[  5800/10000] loss=30.4383  Lc=9.6290  Ls=1.0405\n",
      "[  6000/10000] loss=46.4084  Lc=15.5028  Ls=1.5453\n",
      "[  6200/10000] loss=40.3803  Lc=12.2992  Ls=1.4041\n",
      "[  6400/10000] loss=39.0485  Lc=11.6845  Ls=1.3682\n",
      "[  6600/10000] loss=65.4143  Lc=20.2416  Ls=2.2586\n",
      "[  6800/10000] loss=23.2755  Lc=8.9247  Ls=0.7175\n",
      "[  7000/10000] loss=29.4058  Lc=10.0430  Ls=0.9681\n",
      "[  7200/10000] loss=26.0034  Lc=8.6260  Ls=0.8689\n",
      "[  7400/10000] loss=40.8839  Lc=14.0233  Ls=1.3430\n",
      "[  7600/10000] loss=32.7980  Lc=10.1540  Ls=1.1322\n",
      "[  7800/10000] loss=41.0646  Lc=14.7512  Ls=1.3157\n",
      "[  8000/10000] loss=25.2792  Lc=9.3267  Ls=0.7976\n",
      "[  8200/10000] loss=37.5477  Lc=12.3048  Ls=1.2621\n",
      "[  8400/10000] loss=44.9946  Lc=9.0207  Ls=1.7987\n",
      "[  8600/10000] loss=29.2311  Lc=11.7001  Ls=0.8765\n",
      "[  8800/10000] loss=30.2227  Lc=10.9434  Ls=0.9640\n",
      "[  9000/10000] loss=32.2619  Lc=9.7152  Ls=1.1273\n",
      "[  9200/10000] loss=26.2709  Lc=8.4908  Ls=0.8890\n",
      "[  9400/10000] loss=35.8231  Lc=11.8642  Ls=1.1979\n",
      "[  9600/10000] loss=23.7883  Lc=7.5608  Ls=0.8114\n",
      "[  9800/10000] loss=42.4353  Lc=15.6804  Ls=1.3377\n",
      "[ 10000/10000] loss=33.7884  Lc=10.8772  Ls=1.1456\n",
      "[final] saved: ./Folder/adain_runs4/c1_s20_a1_it10000/decoder_final4.pth\n",
      "\n",
      "=== RUN c0.5_s5_a1_it10000 ===\n",
      "{'lambda_content': 0.5, 'lambda_style': 5.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=19.4291  Lc=11.4650  Ls=2.7393\n",
      "[   400/10000] loss=23.7600  Lc=12.7091  Ls=3.4811\n",
      "[   600/10000] loss=13.7047  Lc=9.7568  Ls=1.7653\n",
      "[   800/10000] loss=12.8761  Lc=9.0844  Ls=1.6668\n",
      "[  1000/10000] loss=14.3809  Lc=12.4811  Ls=1.6281\n",
      "[  1200/10000] loss=15.3759  Lc=11.0633  Ls=1.9689\n",
      "[  1400/10000] loss=12.3637  Lc=11.0980  Ls=1.3629\n",
      "[  1600/10000] loss=16.0634  Lc=11.6850  Ls=2.0442\n",
      "[  1800/10000] loss=17.8477  Lc=14.4911  Ls=2.1204\n",
      "[  2000/10000] loss=15.7783  Lc=11.5846  Ls=1.9972\n",
      "[  2200/10000] loss=11.4758  Lc=11.1767  Ls=1.1775\n",
      "[  2400/10000] loss=13.3662  Lc=11.2883  Ls=1.5444\n",
      "[  2600/10000] loss=20.8428  Lc=17.9573  Ls=2.3728\n",
      "[  2800/10000] loss=11.7837  Lc=10.9704  Ls=1.2597\n",
      "[  3000/10000] loss=13.4143  Lc=11.5477  Ls=1.5281\n",
      "[  3200/10000] loss=8.9156  Lc=6.9407  Ls=1.0890\n",
      "[  3400/10000] loss=20.5054  Lc=17.9494  Ls=2.3061\n",
      "[  3600/10000] loss=15.9968  Lc=13.6395  Ls=1.8354\n",
      "[  3800/10000] loss=16.5208  Lc=13.9009  Ls=1.9141\n",
      "[  4000/10000] loss=15.5178  Lc=13.2036  Ls=1.7832\n",
      "[  4200/10000] loss=8.8027  Lc=8.3158  Ls=0.9290\n",
      "[  4400/10000] loss=11.5895  Lc=10.4000  Ls=1.2779\n",
      "[  4600/10000] loss=11.4401  Lc=11.1498  Ls=1.1730\n",
      "[  4800/10000] loss=8.4093  Lc=7.5029  Ls=0.9316\n",
      "[  5000/10000] loss=12.0049  Lc=11.4961  Ls=1.2514\n",
      "[  5200/10000] loss=14.1345  Lc=12.4720  Ls=1.5797\n",
      "[  5400/10000] loss=10.2083  Lc=9.6074  Ls=1.0809\n",
      "[  5600/10000] loss=12.8814  Lc=12.3375  Ls=1.3425\n",
      "[  5800/10000] loss=10.5770  Lc=9.9572  Ls=1.1197\n",
      "[  6000/10000] loss=7.5909  Lc=7.3190  Ls=0.7863\n",
      "[  6200/10000] loss=14.6884  Lc=11.5608  Ls=1.7816\n",
      "[  6400/10000] loss=12.8852  Lc=10.4166  Ls=1.5354\n",
      "[  6600/10000] loss=9.7241  Lc=10.7317  Ls=0.8716\n",
      "[  6800/10000] loss=9.7114  Lc=9.2493  Ls=1.0174\n",
      "[  7000/10000] loss=11.0372  Lc=11.1934  Ls=1.0881\n",
      "[  7200/10000] loss=9.2593  Lc=9.0787  Ls=0.9440\n",
      "[  7400/10000] loss=9.2695  Lc=8.8273  Ls=0.9712\n",
      "[  7600/10000] loss=10.7782  Lc=8.5364  Ls=1.3020\n",
      "[  7800/10000] loss=10.5023  Lc=9.5923  Ls=1.1412\n",
      "[  8000/10000] loss=12.0551  Lc=10.0235  Ls=1.4087\n",
      "[  8200/10000] loss=9.3014  Lc=8.4868  Ls=1.0116\n",
      "[  8400/10000] loss=8.2623  Lc=7.4640  Ls=0.9061\n",
      "[  8600/10000] loss=8.3036  Lc=8.6331  Ls=0.7974\n",
      "[  8800/10000] loss=8.7797  Lc=8.1475  Ls=0.9412\n",
      "[  9000/10000] loss=12.3552  Lc=12.0654  Ls=1.2645\n",
      "[  9200/10000] loss=10.5077  Lc=7.4863  Ls=1.3529\n",
      "[  9400/10000] loss=7.6118  Lc=7.0505  Ls=0.8173\n",
      "[  9600/10000] loss=8.5787  Lc=7.6398  Ls=0.9518\n",
      "[  9800/10000] loss=10.3475  Lc=9.2060  Ls=1.1489\n",
      "[ 10000/10000] loss=10.8972  Lc=9.8079  Ls=1.1987\n",
      "[final] saved: ./Folder/adain_runs4/c0.5_s5_a1_it10000/decoder_final4.pth\n",
      "\n",
      "=== RUN c1_s5_a1_it10000 ===\n",
      "{'lambda_content': 1.0, 'lambda_style': 5.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=29.7358  Lc=13.4536  Ls=3.2564\n",
      "[   400/10000] loss=27.5941  Lc=15.8694  Ls=2.3449\n",
      "[   600/10000] loss=24.3254  Lc=11.6693  Ls=2.5312\n",
      "[   800/10000] loss=31.5912  Lc=13.9270  Ls=3.5328\n",
      "[  1000/10000] loss=24.4465  Lc=11.9479  Ls=2.4997\n",
      "[  1200/10000] loss=19.4489  Lc=11.0829  Ls=1.6732\n",
      "[  1400/10000] loss=24.9175  Lc=12.5656  Ls=2.4704\n",
      "[  1600/10000] loss=20.3575  Lc=11.7645  Ls=1.7186\n",
      "[  1800/10000] loss=12.7937  Lc=7.2350  Ls=1.1117\n",
      "[  2000/10000] loss=17.9257  Lc=10.4320  Ls=1.4987\n",
      "[  2200/10000] loss=18.0659  Lc=9.5548  Ls=1.7022\n",
      "[  2400/10000] loss=13.7156  Lc=7.3083  Ls=1.2815\n",
      "[  2600/10000] loss=15.4674  Lc=8.1568  Ls=1.4621\n",
      "[  2800/10000] loss=17.1843  Lc=8.9358  Ls=1.6497\n",
      "[  3000/10000] loss=17.7239  Lc=9.1400  Ls=1.7168\n",
      "[  3200/10000] loss=21.0820  Lc=10.7653  Ls=2.0633\n",
      "[  3400/10000] loss=21.3937  Lc=11.2296  Ls=2.0328\n",
      "[  3600/10000] loss=12.2028  Lc=7.1824  Ls=1.0041\n",
      "[  3800/10000] loss=14.0683  Lc=8.1749  Ls=1.1787\n",
      "[  4000/10000] loss=15.1483  Lc=7.8784  Ls=1.4540\n",
      "[  4200/10000] loss=12.6459  Lc=7.1492  Ls=1.0993\n",
      "[  4400/10000] loss=15.6953  Lc=9.4253  Ls=1.2540\n",
      "[  4600/10000] loss=10.9723  Lc=6.1987  Ls=0.9547\n",
      "[  4800/10000] loss=15.1538  Lc=8.6530  Ls=1.3002\n",
      "[  5000/10000] loss=14.8654  Lc=8.1765  Ls=1.3378\n",
      "[  5200/10000] loss=12.5589  Lc=6.8691  Ls=1.1380\n",
      "[  5400/10000] loss=16.1071  Lc=8.4219  Ls=1.5370\n",
      "[  5600/10000] loss=11.9611  Lc=6.7492  Ls=1.0424\n",
      "[  5800/10000] loss=13.0088  Lc=7.5350  Ls=1.0948\n",
      "[  6000/10000] loss=23.3294  Lc=12.1945  Ls=2.2270\n",
      "[  6200/10000] loss=17.5807  Lc=8.5246  Ls=1.8112\n",
      "[  6400/10000] loss=11.5132  Lc=6.4680  Ls=1.0091\n",
      "[  6600/10000] loss=13.6438  Lc=7.0962  Ls=1.3095\n",
      "[  6800/10000] loss=12.0375  Lc=6.9160  Ls=1.0243\n",
      "[  7000/10000] loss=14.5836  Lc=8.8730  Ls=1.1421\n",
      "[  7200/10000] loss=12.6297  Lc=6.6719  Ls=1.1915\n",
      "[  7400/10000] loss=12.6533  Lc=7.1810  Ls=1.0945\n",
      "[  7600/10000] loss=17.2408  Lc=9.2300  Ls=1.6022\n",
      "[  7800/10000] loss=9.6633  Lc=5.8472  Ls=0.7632\n",
      "[  8000/10000] loss=13.4434  Lc=7.4455  Ls=1.1996\n",
      "[  8200/10000] loss=12.4010  Lc=6.6360  Ls=1.1530\n",
      "[  8400/10000] loss=15.6296  Lc=9.2873  Ls=1.2685\n",
      "[  8600/10000] loss=11.5453  Lc=6.8297  Ls=0.9431\n",
      "[  8800/10000] loss=15.6082  Lc=8.6493  Ls=1.3918\n",
      "[  9000/10000] loss=9.4020  Lc=5.5850  Ls=0.7634\n",
      "[  9200/10000] loss=10.3093  Lc=5.5125  Ls=0.9594\n",
      "[  9400/10000] loss=14.7137  Lc=7.9096  Ls=1.3608\n",
      "[  9600/10000] loss=11.3165  Lc=6.3934  Ls=0.9846\n",
      "[  9800/10000] loss=10.6371  Lc=6.1383  Ls=0.8998\n",
      "[ 10000/10000] loss=13.1755  Lc=7.9218  Ls=1.0507\n",
      "[final] saved: ./Folder/adain_runs4/c1_s5_a1_it10000/decoder_final4.pth\n",
      "\n",
      "=== RUN c2_s5_a1_it10000 ===\n",
      "{'lambda_content': 2.0, 'lambda_style': 5.0, 'alpha': 1.0, 'max_iterations': 10000, 'save_every': 5000, 'log_every': 200}\n",
      "[   200/10000] loss=47.9633  Lc=14.3267  Ls=3.8620\n",
      "[   400/10000] loss=39.2074  Lc=11.2347  Ls=3.3476\n",
      "[   600/10000] loss=26.3987  Lc=8.0270  Ls=2.0689\n",
      "[   800/10000] loss=28.0247  Lc=9.9965  Ls=1.6063\n",
      "[  1000/10000] loss=22.5534  Lc=7.1391  Ls=1.6551\n",
      "[  1200/10000] loss=22.5111  Lc=7.3064  Ls=1.5796\n",
      "[  1400/10000] loss=26.4358  Lc=8.8622  Ls=1.7423\n",
      "[  1600/10000] loss=26.2501  Lc=8.6707  Ls=1.7817\n",
      "[  1800/10000] loss=29.4710  Lc=9.5531  Ls=2.0729\n",
      "[  2000/10000] loss=30.2048  Lc=9.8528  Ls=2.0998\n",
      "[  2200/10000] loss=26.2426  Lc=8.2243  Ls=1.9588\n",
      "[  2400/10000] loss=16.5489  Lc=4.8661  Ls=1.3633\n",
      "[  2600/10000] loss=17.2591  Lc=5.8363  Ls=1.1173\n",
      "[  2800/10000] loss=18.7476  Lc=6.3011  Ls=1.2291\n",
      "[  3000/10000] loss=20.4564  Lc=5.5030  Ls=1.8901\n",
      "[  3200/10000] loss=19.7914  Lc=6.4777  Ls=1.3672\n",
      "[  3400/10000] loss=23.7980  Lc=7.5618  Ls=1.7349\n",
      "[  3600/10000] loss=21.5641  Lc=6.7228  Ls=1.6237\n",
      "[  3800/10000] loss=15.4170  Lc=5.0166  Ls=1.0768\n",
      "[  4000/10000] loss=21.3111  Lc=6.9758  Ls=1.4719\n",
      "[  4200/10000] loss=24.6420  Lc=8.1718  Ls=1.6597\n",
      "[  4400/10000] loss=15.8118  Lc=5.0116  Ls=1.1577\n",
      "[  4600/10000] loss=32.2121  Lc=9.6389  Ls=2.5868\n",
      "[  4800/10000] loss=19.8010  Lc=6.1039  Ls=1.5186\n",
      "[  5000/10000] loss=29.1043  Lc=9.2167  Ls=2.1342\n",
      "[  5200/10000] loss=18.8950  Lc=6.3881  Ls=1.2238\n",
      "[  5400/10000] loss=12.4123  Lc=4.2029  Ls=0.8013\n",
      "[  5600/10000] loss=28.3343  Lc=8.8995  Ls=2.1070\n",
      "[  5800/10000] loss=19.5368  Lc=6.5104  Ls=1.3032\n",
      "[  6000/10000] loss=19.8038  Lc=6.5994  Ls=1.3210\n",
      "[  6200/10000] loss=20.1929  Lc=6.7004  Ls=1.3584\n",
      "[  6400/10000] loss=18.4722  Lc=5.9157  Ls=1.3281\n",
      "[  6600/10000] loss=22.6820  Lc=6.9898  Ls=1.7405\n",
      "[  6800/10000] loss=30.0572  Lc=8.8162  Ls=2.4850\n",
      "[  7000/10000] loss=19.1344  Lc=5.9921  Ls=1.4300\n",
      "[  7200/10000] loss=16.6467  Lc=5.5574  Ls=1.1064\n",
      "[  7400/10000] loss=23.1950  Lc=6.8183  Ls=1.9117\n",
      "[  7600/10000] loss=23.1241  Lc=6.5986  Ls=1.9854\n",
      "[  7800/10000] loss=24.8501  Lc=7.5893  Ls=1.9343\n",
      "[  8000/10000] loss=24.2284  Lc=7.7666  Ls=1.7390\n",
      "[  8200/10000] loss=18.1577  Lc=5.8130  Ls=1.3063\n",
      "[  8400/10000] loss=20.1294  Lc=6.1179  Ls=1.5787\n",
      "[  8600/10000] loss=14.0240  Lc=4.6905  Ls=0.9286\n",
      "[  8800/10000] loss=17.8715  Lc=5.9852  Ls=1.1802\n",
      "[  9000/10000] loss=14.9472  Lc=5.0197  Ls=0.9816\n",
      "[  9200/10000] loss=18.8582  Lc=6.1139  Ls=1.3261\n",
      "[  9400/10000] loss=15.2908  Lc=5.0443  Ls=1.0404\n",
      "[  9600/10000] loss=14.3208  Lc=5.0572  Ls=0.8413\n",
      "[  9800/10000] loss=15.9433  Lc=5.2111  Ls=1.1042\n",
      "[ 10000/10000] loss=15.4027  Lc=5.3205  Ls=0.9523\n",
      "[final] saved: ./Folder/adain_runs4/c2_s5_a1_it10000/decoder_final4.pth\n"
     ]
    }
   ],
   "source": [
    "#Adain Hyper 2\n",
    "\n",
    "import os, random, time, json\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models, utils\n",
    "\n",
    "# -----------------------------\n",
    "# Device & Reproducibility\n",
    "# -----------------------------\n",
    "torch.backends.cudnn.benchmark = True\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "class Cfg:\n",
    "    # Paths (adjust if needed)\n",
    "    data_root = str((Path.cwd() / \"\").resolve())\n",
    "    content_dir = os.path.join(data_root, \"content\")\n",
    "    style_dir   = os.path.join(data_root, \"style\")\n",
    "    out_dir     = \"./Folder/adain_runs4\"\n",
    "\n",
    "    # Training\n",
    "    image_size_crop   = 256\n",
    "    resize_shorter_to = 512\n",
    "    batch_size = 8\n",
    "    num_workers = 2\n",
    "    lr = 1e-4\n",
    "    max_iterations = 80_000\n",
    "\n",
    "    # Logging & saving\n",
    "    save_every = 5000            # <-- save grid + checkpoint every 200 steps\n",
    "    log_every  = 200\n",
    "\n",
    "    # Loss weights (total = λc * Lc + λs * Ls)\n",
    "    lambda_content = 0.8\n",
    "    lambda_style   = 58.0\n",
    "\n",
    "    # AdaIN blend strength for target feature (1.0 = pure style stats)\n",
    "    alpha = 1.0\n",
    "\n",
    "    # Resume (leave None for fresh runs)\n",
    "    resume = None\n",
    "\n",
    "cfg = Cfg()\n",
    "os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "# Helper: turn a Cfg instance (class-level attrs) into a dict\n",
    "def cfg_to_dict(obj):\n",
    "    out = {}\n",
    "    for k in dir(obj):\n",
    "        if k.startswith(\"_\"):\n",
    "            continue\n",
    "        v = getattr(obj, k)\n",
    "        if callable(v):\n",
    "            continue\n",
    "        out[k] = v\n",
    "    return out\n",
    "\n",
    "print(\"CFG:\", cfg_to_dict(cfg))\n",
    "\n",
    "# -----------------------------\n",
    "# Basic image helpers\n",
    "# -----------------------------\n",
    "IMG_EXTS = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n",
    "\n",
    "def count_imgs(p):\n",
    "    p = Path(p)\n",
    "    return sum(1 for f in p.rglob(\"*\") if f.suffix.lower() in IMG_EXTS)\n",
    "\n",
    "def first_img(p):\n",
    "    p = Path(p)\n",
    "    for f in p.rglob(\"*\"):\n",
    "        if f.suffix.lower() in IMG_EXTS:\n",
    "            return str(f)\n",
    "    return None\n",
    "\n",
    "print(\"content_dir exists:\", os.path.isdir(cfg.content_dir), \"n_images:\", count_imgs(cfg.content_dir) if os.path.isdir(cfg.content_dir) else 0)\n",
    "print(\"style_dir   exists:\", os.path.isdir(cfg.style_dir),   \"n_images:\", count_imgs(cfg.style_dir)   if os.path.isdir(cfg.style_dir)   else 0)\n",
    "print(\"example content:\", first_img(cfg.content_dir))\n",
    "print(\"example style  :\", first_img(cfg.style_dir))\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class ImageFolderFlat(Dataset):\n",
    "    def __init__(self, root, resize_shorter_to=512, crop_size=256):\n",
    "        self.paths = []\n",
    "        for p in sorted(Path(root).rglob(\"*\")):\n",
    "            if p.suffix.lower() in IMG_EXTS:\n",
    "                self.paths.append(str(p))\n",
    "        if not self.paths:\n",
    "            raise RuntimeError(f\"No images found under {root}\")\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Lambda(lambda im: im.convert(\"RGB\")),\n",
    "            T.Resize(resize_shorter_to, interpolation=Image.BICUBIC),\n",
    "            T.RandomCrop(crop_size),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx % len(self.paths)]\n",
    "        img = Image.open(p)\n",
    "        return self.transform(img)\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Iterates over content images; for each content item, pick a random style item.\n",
    "    \"\"\"\n",
    "    def __init__(self, content_root, style_root, resize_shorter_to=512, crop_size=256):\n",
    "        self.content_ds = ImageFolderFlat(content_root, resize_shorter_to, crop_size)\n",
    "        self.style_ds   = ImageFolderFlat(style_root,   resize_shorter_to, crop_size)\n",
    "        self.style_len  = len(self.style_ds)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.content_ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        content_img = self.content_ds[idx]\n",
    "        style_img   = self.style_ds[random.randrange(self.style_len)]\n",
    "        return content_img, style_img\n",
    "\n",
    "# Build dataloader once; reused across sweeps\n",
    "train_ds = PairDataset(cfg.content_dir, cfg.style_dir, cfg.resize_shorter_to, cfg.image_size_crop)\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=cfg.num_workers,\n",
    "    pin_memory=(device.type == 'cuda'),\n",
    "    drop_last=True\n",
    ")\n",
    "print(\"Dataset size:\", len(train_ds), \"Batches/epoch (approx):\", len(train_loader))\n",
    "\n",
    "# -----------------------------\n",
    "# VGG Encoder & AdaIN\n",
    "# -----------------------------\n",
    "# Map torchvision VGG19 feature indices to friendly names\n",
    "LAYER_NAME_MAP = {\n",
    "    1 : 'relu1_1',\n",
    "    6 : 'relu2_1',\n",
    "    11: 'relu3_1',\n",
    "    20: 'relu4_1',\n",
    "}\n",
    "\n",
    "STYLE_LAYERS = ['relu1_1','relu2_1','relu3_1','relu4_1']\n",
    "CONTENT_LAYER = 'relu4_1'\n",
    "\n",
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    # feat: (B, C, H, W)\n",
    "    B, C = feat.size()[:2]\n",
    "    feat_var = feat.view(B, C, -1).var(dim=2, unbiased=False) + eps\n",
    "    feat_std = feat_var.sqrt().view(B, C, 1, 1)\n",
    "    feat_mean = feat.view(B, C, -1).mean(dim=2).view(B, C, 1, 1)\n",
    "    return feat_mean, feat_std\n",
    "\n",
    "def adain(content_feat, style_feat, eps=1e-5):\n",
    "    # Channel-wise align mean & std of content to style\n",
    "    c_mean, c_std = calc_mean_std(content_feat, eps)\n",
    "    s_mean, s_std = calc_mean_std(style_feat, eps)\n",
    "    normalized = (content_feat - c_mean) / c_std\n",
    "    return normalized * s_std + s_mean\n",
    "\n",
    "class VGGEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    VGG-19 (imagenet) up to relu4_1. Returns dict of selected layer activations.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            self.vgg = models.vgg19(weights=models.VGG19_Weights.DEFAULT).features\n",
    "        except Exception:\n",
    "            self.vgg = models.vgg19(pretrained=True).features\n",
    "        for p in self.vgg.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def forward(self, x, out_keys=('relu1_1','relu2_1','relu3_1','relu4_1')):\n",
    "        feats = {}\n",
    "        h = x\n",
    "        for i, layer in enumerate(self.vgg):\n",
    "            h = layer(h)\n",
    "            name = LAYER_NAME_MAP.get(i, None)\n",
    "            if name in out_keys:\n",
    "                feats[name] = h\n",
    "            if i >= 20:  # after relu4_1\n",
    "                pass\n",
    "        return feats\n",
    "\n",
    "# -----------------------------\n",
    "# Decoder (mirror-ish of VGG)\n",
    "# -----------------------------\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            # relu4_1 -> block3\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(512, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 128, 3), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(128, 128, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(128, 64, 3), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(64, 64, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(64, 3, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.body(x)\n",
    "\n",
    "# -----------------------------\n",
    "# Loss wrapper & style loss\n",
    "# -----------------------------\n",
    "class LossNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = VGGEncoder()\n",
    "        self.encoder.eval()\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def encode(self, x, keys=None):\n",
    "        return self.encoder(x, out_keys=tuple(keys) if keys else tuple(STYLE_LAYERS))\n",
    "\n",
    "def mean_std_loss(x_feats, y_feats):\n",
    "    \"\"\"\n",
    "    IN-statistics style loss: sum over layers of (mean MSE + std MSE)\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    for k in STYLE_LAYERS:\n",
    "        xm, xs = calc_mean_std(x_feats[k])\n",
    "        ym, ys = calc_mean_std(y_feats[k])\n",
    "        loss = loss + F.mse_loss(xm, ym) + F.mse_loss(xs, ys)\n",
    "    return loss\n",
    "\n",
    "# -----------------------------\n",
    "# Utility: (de)normalization & saving\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def denorm_for_save(x):\n",
    "    # x is normalized (ImageNet), bring it back to [0,1] for saving\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=x.device).view(1,3,1,1)\n",
    "    std  = torch.tensor([0.229, 0.224, 0.225], device=x.device).view(1,3,1,1)\n",
    "    y = x * std + mean\n",
    "    return torch.clamp(y, 0, 1)\n",
    "\n",
    "# -----------------------------\n",
    "# Training: one run with overrides  (FIXED cfg copy)\n",
    "# -----------------------------\n",
    "def train_once(cfg_base, overrides):\n",
    "    # Build a dict from cfg_base (even if class-level attrs), then apply overrides\n",
    "    base_dict = cfg_to_dict(cfg_base)\n",
    "    base_dict.update(overrides)\n",
    "    run_cfg = SimpleNamespace(**base_dict)\n",
    "\n",
    "    # Unique run folder\n",
    "    tag = f\"c{run_cfg.lambda_content:g}_s{run_cfg.lambda_style:g}_a{run_cfg.alpha:g}_it{run_cfg.max_iterations}\"\n",
    "    run_out = os.path.join(run_cfg.out_dir, tag)\n",
    "    os.makedirs(run_out, exist_ok=True)\n",
    "\n",
    "    # Fresh model & optimizer\n",
    "    decoder = Decoder().to(device)\n",
    "    lossnet = LossNet().to(device).eval()\n",
    "    optimizer = torch.optim.Adam(decoder.parameters(), lr=run_cfg.lr)\n",
    "\n",
    "    # Resume (decoder-only resume supported; optional)\n",
    "    start_iter = 0\n",
    "    if run_cfg.resume:\n",
    "        data = torch.load(run_cfg.resume, map_location=device)\n",
    "        decoder.load_state_dict(data['decoder'], strict=True)\n",
    "        if 'optimizer' in data:\n",
    "            optimizer.load_state_dict(data['optimizer'])\n",
    "        start_iter = data.get('iteration', 0)\n",
    "        print(f\"[resume] loaded {run_cfg.resume} @ iter {start_iter}\")\n",
    "\n",
    "    global_iter = start_iter\n",
    "    data_iter = iter(train_loader)\n",
    "    decoder.train()\n",
    "\n",
    "    print(f\"\\n=== RUN {tag} ===\")\n",
    "    print({k: getattr(run_cfg, k) for k in ['lambda_content','lambda_style','alpha','max_iterations','save_every','log_every']})\n",
    "\n",
    "    while global_iter < run_cfg.max_iterations:\n",
    "        try:\n",
    "            content, style = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(train_loader)\n",
    "            content, style = next(data_iter)\n",
    "\n",
    "        content = content.to(device, non_blocking=True)\n",
    "        style   = style.to(device, non_blocking=True)\n",
    "\n",
    "        # --- Targets ---\n",
    "        with torch.no_grad():\n",
    "            c4 = lossnet.encoder(content, out_keys=['relu4_1'])['relu4_1']\n",
    "            s4 = lossnet.encoder(style,   out_keys=['relu4_1'])['relu4_1']\n",
    "        t_adain = adain(c4, s4)\n",
    "        t_feat  = run_cfg.alpha * t_adain + (1.0 - run_cfg.alpha) * c4  # blend with content features\n",
    "\n",
    "        # --- Decode ---\n",
    "        g_img = decoder(t_feat)\n",
    "        g_img_clamped = torch.clamp(g_img, -3.0, 3.0)\n",
    "\n",
    "        # --- Re-encode generated (with grad) ---\n",
    "        g_feats_all = lossnet.encoder(g_img_clamped, out_keys=STYLE_LAYERS)\n",
    "\n",
    "        # --- Style targets (no grad) ---\n",
    "        with torch.no_grad():\n",
    "            s_feats_all = lossnet.encoder(style, out_keys=STYLE_LAYERS)\n",
    "\n",
    "        # --- Losses ---\n",
    "        loss_c = F.mse_loss(g_feats_all[CONTENT_LAYER], t_feat)\n",
    "        loss_s = mean_std_loss(g_feats_all, s_feats_all)\n",
    "        loss   = run_cfg.lambda_content * loss_c + run_cfg.lambda_style * loss_s\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        global_iter += 1\n",
    "\n",
    "        if global_iter % run_cfg.log_every == 0:\n",
    "            print(f\"[{global_iter:>6d}/{run_cfg.max_iterations}] \"\n",
    "                  f\"loss={loss.item():.4f}  Lc={loss_c.item():.4f}  Ls={loss_s.item():.4f}\")\n",
    "\n",
    "        if global_iter % run_cfg.save_every == 0:\n",
    "            with torch.no_grad():\n",
    "                c_show = denorm_for_save(content[:2])\n",
    "                s_show = denorm_for_save(style[:2])\n",
    "                g_show = denorm_for_save(g_img_clamped[:2])\n",
    "                samples = torch.cat([c_show, s_show, g_show], dim=0)\n",
    "            grid = utils.make_grid(samples, nrow=2)\n",
    "            grid_path = os.path.join(run_out, f\"samples_iter_{global_iter}.png\")\n",
    "            utils.save_image(grid, grid_path)\n",
    "\n",
    "            ckpt = {\n",
    "                'iteration': global_iter,\n",
    "                'decoder': decoder.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'cfg': vars(run_cfg),\n",
    "                'time': time.time(),\n",
    "            }\n",
    "            ckpt_path = os.path.join(run_out, f\"decoder_iter4_{global_iter}.pth\")\n",
    "            torch.save(ckpt, ckpt_path)\n",
    "            try:\n",
    "                os.sync()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Final save\n",
    "    final_path = os.path.join(run_out, \"decoder_final4.pth\")\n",
    "    torch.save({'iteration': global_iter, 'decoder': decoder.state_dict(), 'cfg': vars(run_cfg)}, final_path)\n",
    "    print(f\"[final] saved: {final_path}\")\n",
    "\n",
    "    return {\n",
    "        \"tag\": tag,\n",
    "        \"final_iteration\": global_iter,\n",
    "        \"out_dir\": run_out,\n",
    "        \"lambda_content\": run_cfg.lambda_content,\n",
    "        \"lambda_style\": run_cfg.lambda_style,\n",
    "        \"alpha\": run_cfg.alpha\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluation: stylize fixed pairs with alpha sweep (after training)\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def stylize_pairs(ckpt_path, pairs, alpha_vals=(1.0,), save_path=\"eval_grid.png\"):\n",
    "    # Load trained decoder\n",
    "    decoder = Decoder().to(device).eval()\n",
    "    data = torch.load(ckpt_path, map_location=device)\n",
    "    decoder.load_state_dict(data['decoder'], strict=True)\n",
    "\n",
    "    enc = VGGEncoder().to(device).eval()\n",
    "\n",
    "    to_norm = T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    to_tensor = T.Compose([\n",
    "        T.Lambda(lambda im: im.convert(\"RGB\")),\n",
    "        T.Resize(512, interpolation=Image.BICUBIC),\n",
    "        T.CenterCrop(256),\n",
    "        T.ToTensor(),\n",
    "        to_norm\n",
    "    ])\n",
    "\n",
    "    rows = []\n",
    "    for c_path, s_path in pairs:\n",
    "        c = to_tensor(Image.open(c_path)).unsqueeze(0).to(device)\n",
    "        s = to_tensor(Image.open(s_path)).unsqueeze(0).to(device)\n",
    "        c4 = enc(c, out_keys=['relu4_1'])['relu4_1']\n",
    "        s4 = enc(s, out_keys=['relu4_1'])['relu4_1']\n",
    "        t  = adain(c4, s4)\n",
    "        row_imgs = [denorm_for_save(c), denorm_for_save(s)]\n",
    "        for a in alpha_vals:\n",
    "            t_blend = a * t + (1.0 - a) * c4\n",
    "            y = decoder(t_blend).clamp(-3,3)\n",
    "            row_imgs.append(denorm_for_save(y))\n",
    "        rows.append(torch.cat(row_imgs, dim=0))\n",
    "\n",
    "    grid = utils.make_grid(torch.cat(rows, dim=0), nrow=2 + len(alpha_vals))\n",
    "    utils.save_image(grid, save_path)\n",
    "    print(\"Saved eval grid:\", save_path)\n",
    "\n",
    "# -----------------------------\n",
    "# Sweep definition & execution\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Define a first-pass sweep over style weights; keep λc = 1, α = 1\n",
    "    sweep = []\n",
    "    for lam_s in [0.5, 1.0, 2.0, 5.0, 10.0, 20.0]:\n",
    "        sweep.append({\"lambda_content\": 1.0, \"lambda_style\": lam_s, \"alpha\": 1.0, \"max_iterations\": 10_000})\n",
    "\n",
    "    # Optional: vary content weight a bit (still α = 1)\n",
    "    for lam_c in [0.5, 1.0, 2.0]:\n",
    "        sweep.append({\"lambda_content\": lam_c, \"lambda_style\": 5.0, \"alpha\": 1.0, \"max_iterations\": 10_000})\n",
    "\n",
    "    results = []\n",
    "    for overrides in sweep:\n",
    "        results.append(train_once(cfg, overrides))\n",
    "\n",
    "    # Save a summary JSON\n",
    "    with open(os.path.join(cfg.out_dir, \"sweep_results.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    # Example: quick evaluation grid for one trained checkpoint (edit paths if needed)\n",
    "    try:\n",
    "        ex_content = first_img(cfg.content_dir)\n",
    "        ex_style   = first_img(cfg.style_dir)\n",
    "        if ex_content and ex_style:\n",
    "            ckpt_example = Path(cfg.out_dir) / \"c1_s5_a1_it10000\" / \"decoder_final.pth\"\n",
    "            if ckpt_example.exists():\n",
    "                stylize_pairs(\n",
    "                    str(ckpt_example),\n",
    "                    pairs=[(ex_content, ex_style)],           # add more pairs here\n",
    "                    alpha_vals=(0.3, 0.6, 1.0),\n",
    "                    save_path=str(Path(cfg.out_dir) / \"eval_s5.png\")\n",
    "                )\n",
    "    except Exception as e:\n",
    "        print(\"Eval example skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f804d3e-bf56-4201-b99b-05f9ab38bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference device: cuda\n",
      "Saved → stylized_full_exact3.png | original (HxW): (480, 910) | output (HxW): (480, 910)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'stylized_full_exact3.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== AdaIN inference (no crop, preserve exact size) — self-contained =====\n",
    "import os, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models, utils\n",
    "\n",
    "# ---------------- Device ----------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Inference device:\", device)\n",
    "\n",
    "# ---------------- Core helpers ----------------\n",
    "def calc_mean_std(feat, eps=1e-5):\n",
    "    B, C = feat.size()[:2]\n",
    "    var = feat.view(B, C, -1).var(dim=2, unbiased=False) + eps\n",
    "    std = var.sqrt().view(B, C, 1, 1)\n",
    "    mean = feat.view(B, C, -1).mean(dim=2).view(B, C, 1, 1)\n",
    "    return mean, std\n",
    "\n",
    "def adain(content_feat, style_feat, eps=1e-5):\n",
    "    c_mean, c_std = calc_mean_std(content_feat, eps)\n",
    "    s_mean, s_std = calc_mean_std(style_feat, eps)\n",
    "    normalized = (content_feat - c_mean) / c_std\n",
    "    return normalized * s_std + s_mean\n",
    "\n",
    "@torch.no_grad()\n",
    "def denorm_for_save(x):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=x.device).view(1,3,1,1)\n",
    "    std  = torch.tensor([0.229, 0.224, 0.225], device=x.device).view(1,3,1,1)\n",
    "    y = x * std + mean\n",
    "    return torch.clamp(y, 0, 1)\n",
    "\n",
    "# ---------------- VGG encoder up to relu4_1 ----------------\n",
    "LAYER_NAME_MAP = {1:'relu1_1', 6:'relu2_1', 11:'relu3_1', 20:'relu4_1'}\n",
    "class VGGEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            self.vgg = models.vgg19(weights=models.VGG19_Weights.DEFAULT).features\n",
    "        except Exception:\n",
    "            self.vgg = models.vgg19(pretrained=True).features\n",
    "        for p in self.vgg.parameters():\n",
    "            p.requires_grad_(False)\n",
    "    def forward(self, x, out_keys=('relu1_1','relu2_1','relu3_1','relu4_1')):\n",
    "        feats, h = {}, x\n",
    "        for i, layer in enumerate(self.vgg):\n",
    "            h = layer(h)\n",
    "            name = LAYER_NAME_MAP.get(i, None)\n",
    "            if name in out_keys:\n",
    "                feats[name] = h\n",
    "        return feats\n",
    "\n",
    "# ---------------- Decoder (must match training) ----------------\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(512, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 256, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(256, 128, 3), nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(128, 128, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(128, 64, 3), nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(64, 64, 3), nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1), nn.Conv2d(64, 3, 3)\n",
    "        )\n",
    "    def forward(self, x): return self.body(x)\n",
    "\n",
    "# ---------------- Robust checkpoint loader ----------------\n",
    "def _strip_module_prefix(sd):\n",
    "    if not any(k.startswith('module.') for k in sd.keys()):\n",
    "        return sd\n",
    "    return {k.replace('module.', '', 1): v for k,v in sd.items()}\n",
    "\n",
    "def load_decoder_from_ckpt(ckpt_path, device):\n",
    "    assert os.path.isfile(ckpt_path), f\"Checkpoint not found: {ckpt_path}\"\n",
    "    dec = Decoder().to(device).eval()\n",
    "    data = torch.load(ckpt_path, map_location=device)\n",
    "    last_err = None\n",
    "    if isinstance(data, dict):\n",
    "        for key in ('decoder','state_dict','model'):\n",
    "            if key in data and isinstance(data[key], dict):\n",
    "                try:\n",
    "                    dec.load_state_dict(_strip_module_prefix(data[key]), strict=True)\n",
    "                    return dec\n",
    "                except Exception as e:\n",
    "                    last_err = e\n",
    "        # raw state_dict?\n",
    "        try:\n",
    "            dec.load_state_dict(_strip_module_prefix(data), strict=True)\n",
    "            return dec\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Could not load decoder weights from {ckpt_path}. Last error: {last_err}\")\n",
    "\n",
    "# ---------------- Inference that preserves exact size ----------------\n",
    "@torch.no_grad()\n",
    "def stylize_preserve_size(\n",
    "    ckpt_path: str,\n",
    "    content_path: str,\n",
    "    style_path: str,\n",
    "    out_path: str = \"stylized_preserve.png\",\n",
    "    alpha: float = 1.0,\n",
    "    max_long_side: int | None = None,   # None = keep original; or e.g. 1024 to downscale for memory\n",
    "    style_max_long_side: int = 512      # style can be smaller\n",
    "):\n",
    "    assert os.path.isfile(content_path), f\"Content not found: {content_path}\"\n",
    "    assert os.path.isfile(style_path),   f\"Style not found: {style_path}\"\n",
    "    os.makedirs(os.path.dirname(out_path) or \".\", exist_ok=True)\n",
    "\n",
    "    dec = load_decoder_from_ckpt(ckpt_path, device)\n",
    "    enc = VGGEncoder().to(device).eval()\n",
    "\n",
    "    # No crop transforms\n",
    "    to_norm = T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "    def load_no_crop(path, limit=None):\n",
    "        im = Image.open(path).convert(\"RGB\")\n",
    "        if limit is not None:\n",
    "            w, h = im.size\n",
    "            scale = min(1.0, limit / max(w, h))  # downscale only\n",
    "            if scale < 1.0:\n",
    "                im = im.resize((round(w*scale), round(h*scale)), Image.BICUBIC)\n",
    "        t = T.ToTensor()(im)\n",
    "        return to_norm(t), im.size  # (C,H,W), (W,H)\n",
    "\n",
    "    c_t, (cw, ch) = load_no_crop(content_path, max_long_side)      # (C,H,W), (W,H)\n",
    "    s_t, _        = load_no_crop(style_path,   style_max_long_side)\n",
    "\n",
    "    c = c_t.unsqueeze(0).to(device)  # [1,3,H,W]\n",
    "    s = s_t.unsqueeze(0).to(device)\n",
    "\n",
    "    # Pad to multiples of 8 so decode returns same spatial size\n",
    "    H, W = c.shape[-2:]\n",
    "    mul = 8\n",
    "    newH = ((H + mul - 1) // mul) * mul\n",
    "    newW = ((W + mul - 1) // mul) * mul\n",
    "    pad_top    = (newH - H) // 2\n",
    "    pad_bottom = newH - H - pad_top\n",
    "    pad_left   = (newW - W) // 2\n",
    "    pad_right  = newW - W - pad_left\n",
    "    if newH != H or newW != W:\n",
    "        c = F.pad(c, (pad_left, pad_right, pad_top, pad_bottom), mode='reflect')\n",
    "\n",
    "    # Encode, AdaIN, blend, decode\n",
    "    c4 = enc(c, out_keys=['relu4_1'])['relu4_1']\n",
    "    s4 = enc(s, out_keys=['relu4_1'])['relu4_1']\n",
    "    t  = adain(c4, s4)\n",
    "    t_blend = alpha * t + (1.0 - alpha) * c4\n",
    "    y = dec(t_blend).clamp(-3, 3)   # [1,3,newH,newW]\n",
    "\n",
    "    # Remove padding back to original size\n",
    "    if newH != H or newW != W:\n",
    "        y = y[..., pad_top:pad_top+H, pad_left:pad_left+W]\n",
    "\n",
    "    y_vis = denorm_for_save(y)[0].cpu()\n",
    "    utils.save_image(y_vis, out_path)\n",
    "    print(f\"Saved → {out_path} | original (HxW): {(ch, cw)} | output (HxW): {tuple(y_vis.shape[-2:])}\")\n",
    "    return out_path\n",
    "\n",
    "# ---------------- Example call (EDIT THESE PATHS) ----------------\n",
    "ckpt = \"/workspace/Folder/adain_runs4/c2_s5_a1_it10000/decoder_final4.pth\"  # ensure the filename matches your saved model\n",
    "content = \"/workspace/content test2.jpg\"\n",
    "style   = \"/workspace/Van_Gogh_-_Starry_Night.jpg\"\n",
    "stylize_preserve_size(ckpt, content, style, out_path=\"stylized_full_exact3.png\", alpha=1.0, max_long_side=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8431e2-6dba-47b7-9ed4-84e65ab54bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
